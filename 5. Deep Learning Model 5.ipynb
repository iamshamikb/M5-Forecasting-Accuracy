{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New\n",
    "# Models and scores\n",
    "# Total no of submissions this competition has got is 5558\n",
    "#           Private   Public   Private_Rank   In_top%\n",
    "# ML models\n",
    "# 'M0.1' :  5.09      5.16\n",
    "# 'M0.2' :  2.67      2.84\n",
    "\n",
    "# 'M3.1' :  0.91      0.86     1980         35.62%\n",
    "# 'M3.2' :  0.91      0.94\n",
    "# 'M3.3' :  0.85      0.91\n",
    "# 'M3.4' :  0.89      0.94\n",
    "# 'M3.5' :  0.94      0.86\n",
    "# 'M3.6' :  0.87      0.88\n",
    "\n",
    "# 'M4.1' :  4.90      4.99\n",
    "# 'M4.2' :  4.90      5.29\n",
    "\n",
    "# 'M5.1' :  0.84      1.26      \n",
    "# 'M5.2' :  0.95      1.11\n",
    "# 'M5.3' :  5.05      4.93\n",
    "\n",
    "# 'M7.1' :  0.73      0.92      757          13.62%\n",
    "# 'M7.2' :  0.94      1.08      2150         37.78%\n",
    "\n",
    "\n",
    "# Neural network models\n",
    "# NN M3  :  1.12      0.99\n",
    "# NN M4  :  0.82      1.21      1933         34%\n",
    "# NN M5  :  1.90      1.70\n",
    "# NN M6  :  3.58      4.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Deep Learning Model 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First score is Private and second score is Public score"
   ]
  },
  {
   "attachments": {
    "Screenshot%20-%2014-11-2020%20,%2012_05_43.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvYAAABRCAYAAAC5Z+JfAAAABmJLR0QAAAAAAAD5Q7t/AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAcHRFWHREZXNjcmlwdGlvbgBjaHJvbWUKMTQtMTEtMjAyMCAsIDEyOjA1OjQzCkNocm9tZSBMZWdhY3kgV2luZG93Ck01IEZvcmVjYXN0aW5nIC0gQWNjdXJhY3kgfCBLYWdnbGUgLSBHb29nbGUgQ2hyb21lgCxcvAAAGY9JREFUeF7t3c1PG+e+B/D8Gdl22WWX2WYZscoykleoi6NIbGBFjlR0lBNVjXsESlKEQtC9bl5qekxoCReuA8iQGB/iA9Rc17YgNgHkYl9Sm1qTOG5A3/M882LPjMfGJk6VTr4fyUrteXvmpcn3efyb8RkQEREREdGf3hn7B0RERERE9OfDYE9ERERE5AIM9kRERERELsBgT0RERETkAgz2REREREQuwGBPREREROQCDPZERERERC7AYE9ERERE5AIM9kRERERELsBgT0RERETkAgz2REREREQu8AcH+7coH5ZQfHNsn3B6x4dYnl3H9HbFPqVt5ecJ3JzdRlF9d4xySbRVeWuby+S4gqLYn/K7b/o90497qUlDlZJtX/Rl7K9mx4OIiOi0ygoUpcm/U7qKIudzejkse1RBYS+J5F4BlSP7REMFSj6NWDoHp1UYKoVdJFO7KDSZqaLkkI6lkWsyD51Ci9eGoaXz0JFro+JwHSrO85YL2E0lsVtwmtg5f3Cw38bVr+Zwca5gn3B6BwlcEus8N5W1T2nbWmAOZ7wRTB/KdwXcGxHvx7dtc5nsx3FRbPtqzD7hQ6Md9zNfhRH41T5NymP0lpxu3hdjGdur2fEgIiJqm4LdxWH0dXWhq8uPpH2yRQGhL+V8Ti/rspX0I1z73DT98yEE92yhKh/FnX5PbR5PP3zrinWe8i6Cg92m7XjQfzcG61wKYnf74TG1p3swiN2yZSZqWzvXhpRDdKTPcl10D4bFp1YduzZ+CaLftC3jdW3RnHMrSP94Dd1/0LXx5w/2kugdlTvxJYAcga+OSLsx2M/hwmzePhFIrOIzfXp1Xw5TuCzeX4lwxJ6IiN6XXTwS4cnTfwf+sf6Wwlv9iH0aj/7WBc830VrYrsTg83ShZyyKghyNPcoh9LUIaT1i/dX8lkPwCxG0vnyEXXVBBckHMhReQ+jAmAdIB3rEcncQ1aOL8kKEQhHOhpZrIU9ZHlKXe/RC/6wgQmGP2H4gXZ2H2tX+tZGeFOfPcx1B03nw9Xahb9J0Hjp4bSDlF58NI1xoPGJfiflEh68Hd1b0CygfwnW5/QdJvI+x+/aDfaWA5bl19I6GcPG/VnEvrg5vq4obG/AGUsiYZs8sr8I7u6OXtxjBPo9MZBWXh5dweXwD8/laWDTWkTjYxujdsLqNwPPXesnNCrpvhNE7u41iNcjnMR1YxehGSX9/jOLOJkbHI7iozruJjLmD1XL7a8G+GI+r83ffXUdg07Qyp2B/mEVgSm/nVBxrB631OCz7Lds+HIF3KYtqh+5wB6NiP6cz2nFQj10ggYSt8+hMO+7nhhZw5saG5fzInuT8fbGfgwtquK/uS1bu2xLutfNFiDi282rb5LHawPSOuXGNz0txXe57AmtvTLPr+xvYZEeCiMi90giOx9SAVVi81lJ4s6uIcNXT1YcJU3ZTVobFuoYQ/q32GQ5CaiC/s67HqfSEWK7HshzE1v0idPXPGmO8BURv96P/R/NM+rcGD2otTf8o5rktgqJpruQDGQxDls+oHe1eG2lMyM6UOcRDX9bjQ0w/7Z27Nox1+9G4+6Yg+o24DgbDlm94tP25U21TJ7UZ7AsI3J7DWRHMbi49FwE2jHMiDF5+ooXq/bklnPkqimXTEsvjIjSOxLGvvtMC5mdDIVwYWxFhTgZgWf4iA6QWgLV1LODcSBhXTNO7b4uwOC46CXeX8IkMqT/s6VuwfgtQjkfVNl0cj2M6EseVYbH80CrW1NW303492IswfGFEtnUVvfK9aNvV2Gtt0/ZgL8LwJe8cPhHzj87F4R0L4axp35qp7vetJfSKbV2Ry5r2y9jWOXHsLt4Vx2E8jPNe87FtRjtGV5cS6Bbb8CZM7flVfjaHK7Mb1n2JRdXSndHVBG6K9ngDtk6NnSK2MaQd2yvV9teOVdPzsrOBC7IN0doVXnwSblI6REREbtNaeLPTQrZltB56qP57yFaCkUPwr2LecS2Gadvz2bZXQWxMLPt1uHEgr4iA12Mvt7DT22UK/3R6rV0b6brgLWlBvjbS3slrIzfbr47qx/4dxERgAhM/hpC0XBbiWpGlOQu2YiC1hMcD/6b1405oL9gbIXDVGEU9RnHzOdb0EfdWg/2Z0YQ+gi8c78E7KAKhXvKircMU6PRtnp8x4usxlr+rX6cRgNU6+VumUWklj+WNvDbC31b79WA/aHQKpBICo6ZtW4K9PvJt3jd9fmPfmtG2HcLotrGx15j21W/rQvU4iLAciYhlRMfhxGSvB/uY1saz959XvwnIzIa0fVRH6GvBXgvWopNyK6IG9d7bC2pH41LI+S8ydT3eCOarf7O+xvx4COfvptTj0fS86Me61q4SpsfE/GPaskRE5H6thTcrp9F6yXm03DrS3mh7zssaKlpJRq8f6SajrbnF6/B4riNsLtugU2t0rqxE8P5vj3pukkYWKYtg3avVtftT2kfO5/d014b6vqsbA9/4RLD3YUjW5IvzHqpWPevB3t4J1L8hMNrUSe0Fe33EW46gyzKT6VTe8kSYVoO9vcZeDX3DcTX01a+jfplm6zRGhs+PrWB0aQeJX83/57XTfuca+/2QnGcFyzKQWoL9Dq56xXbHE5hffV593ftuoaVR9fr9tu2n/dsBSR1VbyfYQ6+nNzpO2k2zat290/rfmI/da9GhEvvijWr7bqEf1++27ROqmp8X0ZFYEh0J7wrmZTmOUd9vGsEnIiJ3axSmGnMerZfsAUxzuvBWI0L9eL8a2GvBrV7uyRC6RWfDn+K/YZ3S6FzV+S2m1tR3ef6C/r/24y+ePtx5PCFC9LXqOXM+v+9wbVieqKPX5o/F9Pr5Dz7YQ69Rl/XxC/hUloJ4Q9VyixPDqR4wjdIXQ2ZGHzWG0zraC/bVWu67YZwfnNNGnUcTyBhhtOX2a8H+s2rJj6a8IkfJw9qTcyxhWC8zuq2V7Vhe1XsMGqvf7/cU7MXaRm/oYd4c8p3Wb9dwe86dIKsTzospzKvfFhghn4iIPgqNwlQj2mj9AIK/2KcA6XEPuv4atJVbWGuwC0+uo77OWa+JrussVLA7K0fhBzDRZKheWfehT4T64RX7c1joXbR1bRwp2E3FEIslsSvr6H/2Qd7gGtVPaOevDSu1PKdnQq+7dy4Pcq7h74xTBPtK7Qk0xy+1QKeHTy2c6qPZKls5iRF+H5rDsl7eopdd1Adce3A/OdiX39RuuCyvr1hvCj2x/bYRe0tpzTHWHi5UOyHWMKx3BCz7JlRau/mzfr/fV7A3ym9WcPWuqfzFtn71pucZ45n+GnVU3ejUWBxrbTWX2gjFzHPMx1/q5TUnnBdZyiTbM55CYKy18iUiInKPtsKbMVpfHRm10p5EYgv9vwQx0OWBz0hr9vdSOYY7IogNPLZVYC+IUH/CKLzys1+Eeg+uLzLUd1pr14aC5OMJTKzsmj6TpVM9lptXO3dtFBCbltszn2+9HKhah6+//8LakcjNDlhu6O2k9oK9fpPjpeC+Fo4LO/DeEiHMt6kFQP2xiefup5DI57E8FdZGxW0hXN5Q6t0ooHhYwNpcpMkNrLVlWgv2ep37UBTzhbfq4yv3Q2H1Js6bz3Fi+52C/VlvCJeX9tVHPWZWo7jgNd24awvDcqRZzn91VZb4vEV5bxNXhhzCvoP6/X5/wd6410DerFu9kda2/rJYtzyXl2b2sC/2fT+1gW5vrSNQjq+qT7cZNYbcU6vqeTTPL28k1o7VCedFV46uiOM3p35uucGXiIhczzm8FRD+ph/XHlifG+8YzizSmOgVwf9vfsTyCpR8DP6/yfprYyRVkiOw8rNhhNIFKIU0QvIZ6J5hROVIr06tl+8SgW48ilhMjgTrr81CtVMhvz2Qz1r/yzdB6zyx3aaju9SaVq8Nbb4++JblD4nlRNCXz8AXHbJNc4Lu3LWhPV5zAP5YDopSQFp95r4Hwyums56eUD8bGI8hpyjIxfwY8NgewdlB7QV7HCPzJKI9jUUNhvIJMOtYM90wuTalPbVGfWZ6YBvTDiH8akT8KZ92o893cWqvejNnfcBtJ9gLyh5uqk+v0V8iaPc+eakv2bz9TsH+YnBb+0ZBn/+8L1UrH6kL26+RmNU7M9X5E8i00COr3+/3GOyNoG2+Mbhu/W+RWVpROzLGvly4X9uXYiSi3kx7xXg0lCy1WdE6Po7Hqul50R1vq/cpWG9YJiKij4FzeNvFIxnCLE8x0eqYG43WV9l+YKj7CxHkTKFMVU7j0Ze1H5/yXLb/UFGTH8Squ4nS6WXfHzqN1q8NxfpjUJ8P4I5TWVRHrg1JQTJg2p6nH3cWd+uuy9zKHfR7jGuiGwO2jmontRnsDW9Rlj9W9OZd0tcxyqWS5ebVjnqjoHioP5ayzinar7Qxv/yhq0PrvmnB3RRsqy9rmD8ttRNQt+65lm7cbU47Vq2fpxOObdPzQkRE1FnqD1oZo4eNlOUPC7X8Dx198Cotnc/OXRutbE/Oo6Biudm2804Z7KltaqC1/Yqr+upQyJUdj7p1i1fppAuNiIiIiNyAwZ6IiIiIyAUY7ImIiIiIXIDBnoiIiIjIBRjsiYiIiIhcgMGeiIiIiMgFGOyJiIiIiFyAwZ6IiIiIyAUY7ImIiIiIXIDBnoiIiIjIBdoO9q9eRDA1PWV6RbDzyj6Xk1fYWW513g+bPAaRFx3YkUoB81MRXLwRwvkbYVxdyqJ4rE3afxJB75OCdf4OKq9EcHZoHQn55iCFXl8K+/aZbGSbzqttla8lXB7fwPKB3uA/hIJp3xzOTWXtE4iIiIg+em0H+1JyCotbJVQqlerryD6To1fYehzElmL//M/n1VYQwa13DfYlTI/N4dLMHvaV1ygf5jF9fwHnfthTp+7PLeHi3PsL9rJTkdjRT8Z+HBdH4icHe9GmM/c3UTwsqa/MxjouDUWx/MY+53uU30fm8I/sTBARERH9ObQd7HOrI1jL2z9t4PgVsqkYYj8lsVMqWoP97yVkt+JiWgzJXdFRUD88QjEdw9ZLc1ehiJ2fMiiqH1VQ2k2qy8S3DvRlHDiuW2dp0xFKL5LIVWcwrz+HVw3yoxbsxXr3tXlbb7/ZNq5+JUKx+SMlj+X4S5ShB/tgFomldXgDqxhdNYf8YxQ3UxgVn3un4ljOv61OKW5sYDqj6MttYF5OO8wiMCXnTSBhhOLDHYzO7ojWoS7YlxNxeOf2tGkmarAf3zZ9cozl7+ZwNW68f43Mahw3ZbtmNy0BPLMsR/cLmJ9dVds1vfe6Ok3dn51Nx/1Rl8tq7R/dKKn7J/+syu/gntw3uU6jo9LKNCIiIiKXaTPYy1H3GaylRKCNPsOz/xOBtWG6PkDs4SSepnIovSoiEw1i8p96sD86wJoxrSJC+OoMJjcO1KWOss9wfyVb+xYgv1Z9f7AxhZn1rFjmFQ6S89b5DE3WXd+mRcz8j9HZOBKdFrl+EXZflZBLPcXUwhZMEbJKBvvA7KI4Dtp6dtZnMLWaU9vSrP1WeYzeWsBlGaAdjqEM0Z8NRXBzdR+ZzCauDs/hckRrzX5oCZ8MR0WAL2A/FcfloTCmf60td24kKsJvXoTsKC4MhnDRt47lPdFp+GEJZ0cT9WHe9N/lmFjmluhwOOTgumB/+BxXRBunD+WbCtYCCzjnE0F8r6Rte2gVa3q2Xx4X00ZWEBBtVkf6vUu4p/ck5DbP6/uTEcH98o0lBPRp2nIRjEaeYy1bsX6TkY3j0o2Iuq/76jEKiU6GfjCbTSMiIiJyobaDffbnGJLbB2poluF38uEacr/b5xMBdy+Cb0XYrRGh2gj26gymqFvaQvDxFrTilhzWHjxDVp18hOzKfTxT37xCZmEKcT3AqhqMqDdad9M2/ZYUIT9pCvLmbVvJYD8S3jGF9RKS08a+NWq/AyWLwHgY57xzODcsQnwkX6uxV0fsX9bmXV+pherjCsrVjKqPmse0d9blCrg3EsLotjGv6VsCh2CfSKziYoNQL6nB3rug1dgPLeDsP5ZwM27q+lREu6rn5CXuDdfC+/L4HK6s107Y2g+iU/NELis7OGEETOe1HIngM70kyb5cLdhXMH9/Ad6E6SJ4vo7zYynRcWk2jYiIiMid2gz29Q5+CuDpi/qR0Po6dGuNfeX/txD/16J2A+5DP76tBnttnZG9Izn8jWcPYzDG249exhF8cB+Tj5/iWSrbsFSm0bqbtim/hhFL6Hea3/T5pnUs31yi1Kj9jb1FeW8Ho74FnAvs1EpxzDX2sWgt2Ct5TM+u4PKwFrA/9dqCfXU5Gexr4bppsB9cUDsY3UtO31Fo6kbsC3sYvW0aCT+QpS8r6NaD/6emUXkZ0I02SrV2yjaJjk31plzxGpyrbqfxcnLf5vDpkGk52dlQ96nZNCIiIiJ3ajvYH1Wso8+lzVbDbwlb/6uH6F/jIpzHcfBKX5diHrEXXsYQ+FcWlewzTP5UH4uP5LcFyacIWEbYdU3W/So9j6lkgzbJYB+1Bnu5b/Np530LVMt7pCNk/xVAzBgoP6H9qsprFEu2DtHxNq54o1iDPaDDFOxLmBYdgN7lPIpvtJ6NOfyeOtjfWEfiUEy/IebPOveY6oI99KfriM4IkMXNoSXcTBX0bxOs224c0GWbVrDsvMkmy+nrd3xATrNpRERERO7UZrDXSleq2fj3HNYeziD5m2UmjSxtMZfpyPcjziH61fZTy4i9UdoSfDxlWncJmXAMWWN9v+/g6bdr9aPhzdatZDD/sPbIzUp2DVPfGnX/WTx7MI+tFvZNLcX557Pavslyn3+aR+ad2m/zawLdXlmfbiTaYxRXV/CZXgPfONjbQmtlD96hDgR7U439OfmkG4dynLpgf6xg/rsFfZTfFtAPErjc0oi9LJuZQ2/E2OAxMqEoruo3CzdeDsjMhnDB9OjLcmwdvXNZ9RuPZtOIiIiI3KjNYC/ybzGJxe/9mJyegv/BFCIv6sbMq0rpRfi/n8TU9CRmwjvYWjVKcURID/nhn5rClHgtrj+zjtjLOVIzGLGNyJfkM/TV9U1hUoRueTNlvebrPipuIfJYPn8/iMjWDuKm8iC11Efsm7r+7xvvm/ptxM9bWJvVnuXv/z6IuOVJOM7ttxJBfiWKC7K+Xi8/+eRWFPP6c+EbB3v9ZtN/6LXuYpmrvs4FezVYi3V8cjuOjG0UXQ32X83VXt4FXAps6/cFyEAexqdqu8RrLIorthr7RgEdyh5ujixopTOyhGdkHWv6OWm63PFLTPtC+HRQltuI5W6IjpLxbUOzaUREREQu1HawN9hLcho6PkLF4eZa1e8VNFqNDMZOJT6y7KXSaCGzRuu2ZDtTKY7JUcvP5m98HBq33+4tyvK58ErtEY8tOa6geGh+ZOQHwqnEqFVvlGp5USOZmZB+062J3Gaj49dsGhEREZGLnDrYvzeVA2S31jDzIFIru+mU8g6efj+Dte0cDl7mkPkpCP9CxvJNwTt7n+3/yBVj6+geCmFUlvQTERERkcWHF+zLRWSz8hn09gkdIp9tb/x41fZBwyfrnNr7bv9HrJh5jmX+0BQRERGRow8v2BMRERERUdsY7ImIiIiIXIDBnoiIiIjIBRjsiYiIiIhcgMGeiIiIiMgFGOyJiIiIiFyAwZ6IiIiIyAUY7ImIiIiIXIDBnoiIiIjIBRjsiYiIiIhcgMGeiIiIiMgFGOyJiIiIiFyAwZ6IiIiIyAUY7ImIiIiIXKDtYF9RFCgV+6caOa1ypL85qkBpNGOzadC3UbZ/aqIuL7Zl/qysqJ9ZXs3WQURERETkIm0G+wJCX3ah64sgcvZJ+jR/Sn+b8qOry4M76w4BXk77MiSWcKJvo2cCafskXe7xgFj3NYQOjE8qiI2JZbpsrwdJ82JERERERK51umAvQnPfpD12OwV7Ma9nGNHfLDO2FuxFp8AXc+gUiLg/0SOnm4O9bdtERERERB+ZUwX7a4EJDHv64N80B2+nYO/DxGQfPF+HrSG+hWA/NDiErsEwFNvUSswHzxcDGLAE+yT8lvdERERERB+X0wX7xQIq63fg6fUjWa1jdwr2YjpyCH7hwfVFU/FOC8Hevx6DzzOA4C/maQrCgyL0L4etQV6JYrhrGKFUGI9Ep2PixxCSzisnIiIiInKlUwd7WdeevNuDvgdJ/SbWRsFeyIdwzXMdobxp2knBXqwnHehBT8BU8vNLEAMeH2IV2wi9WP/1z7txbewRQv+OIvTgGrq7+sQ6nEp5iIiIiIjc5x2CvVAWAbu3B76fZYBuEuyF3OJ1eESYV8ftWwz2tSCvTUlPGkH/5NIbZWUYHsebfImIiIiI3Ofdgr1QESG9z3MHsXLzYC+iPUJfezAwm2s92FdLb2Slvbxp1ijNOTnY4yCEa13DiNqL9ImIiIiIXOidg70syUmP98HzzQT8f28W7IWDMK57+jAR8LUY7I2bZYPYlX9Wb6a1BvvKizAmHietN9r+EkS/fftERERERC7VgWAvpTHRqz0Gs2mwh14iIx+D2WKw10bqPfB4zI+/tI3Yq6PzffDH9Ghf0b4d6BtPW3/EioiIiIjIpToU7KHVw7cQ7LUfk/K0Eez1H6Sy/GBVfSmOsvkI1z43fpyqGwNjUdbXExEREdFHo81g/+GrKAoqR/ZPiYiIiIjczXXBnoiIiIjoY8RgT0RERETkAgz2REREREQuwGBPREREROQCDPZERERERC7AYE9ERERE5AIM9kRERERELsBgT0RERETkAgz2REREREQu8B9TVOhPShZ9HwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot%20-%2014-11-2020%20,%2012_05_43.png](attachment:Screenshot%20-%2014-11-2020%20,%2012_05_43.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/18599/1236839/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1605126035&Signature=aOgEZg5SLywSpDwccQBkRpQIFVxEOO814DAfMApvZdrwaTZDacrU45tsdAJqHsR3CLdNPfl81dc4YQyqGZ1SGXA5xHmdFaZhtAVnZbH7g2Tu8JCsQJArFgLcBbbTR2LLEYoztwKxFxu9Poyv9zNdAVTRuUQK6T98XACU5UCBw3GHj2nzXqmy5VCELiGH2ICLVGK3R5jzuAc7ddmXlnIDnWQqmteLGJnevCHqEjEsgTrwIGBbE2%2BBelWzZ4lQ2KMR0HAFluPiNUyV%2FJfY8leWijKkvy30pm4vibVevGvhvJR5%2BU2eyqfHdHZY4JVgrv0Y7%2BLUTeC7LpESnXGMsGZ4Yg%3D%3D&response-content-disposition=attachment%3B+filename%3Dm5-forecasting-accuracy.zip\" -c -O 'm5-forecasting-accuracy.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip m5-forecasting-accuracy.zip\n",
    "\n",
    "# !apt-get update\n",
    "# !apt-get install wget\n",
    "\n",
    "# ! pip install pandas\n",
    "# ! pip install calender\n",
    "# ! pip install numpy\n",
    "# ! pip install datetime\n",
    "# ! pip install matplotlib\n",
    "# ! pip install collections\n",
    "# ! pip install random\n",
    "# ! pip install tqdm\n",
    "# ! pip install sklearn\n",
    "# ! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval\n",
    "#         xtr_from, xtr_to, ytr_to = 116, 453, 481\n",
    "#         xtr_from, xtr_to, ytr_to = 481, 818, 846\n",
    "#         xtr_from, xtr_to, ytr_to = 846, 1183, 1211\n",
    "#         xtr_from, xtr_to, ytr_to = 1211, 1548, 1576\n",
    "\n",
    "#         xte_from, xte_to = 1604, 1941\n",
    "# val\n",
    "#         xtr_from, xtr_to, ytr_to = 88, 425, 453\n",
    "#         xtr_from, xtr_to, ytr_to = 453, 790, 818\n",
    "#         xtr_from, xtr_to, ytr_to = 818, 1155, 1183\n",
    "#         xtr_from, xtr_to, ytr_to = 1183, 1520, 1548\n",
    "\n",
    "#         xte_from, xte_to = 1576, 1913"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import activations\n",
    "from IPython.display import clear_output as cclear\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "class terminate_on_acc(tf.keras.callbacks.Callback):    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs['loss']\n",
    "        if loss < target_loss:\n",
    "            self.model.stop_training = True\n",
    "terminate_on_acc = terminate_on_acc()\n",
    "\n",
    "n_steps_in, n_steps_out = 337, 28              # input is 1885 days, output 28 days\n",
    "n_features = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test(df, dept_df, model_no):\n",
    "    if df.id.iloc[0].find('evaluation') != -1:                       # if evaluation data\n",
    "        if model_no == 1:\n",
    "            xtr_from, xtr_to, ytr_to = 116, 453, 481\n",
    "        elif model_no == 2:\n",
    "            xtr_from, xtr_to, ytr_to = 481, 818, 846\n",
    "        elif model_no == 3:\n",
    "            xtr_from, xtr_to, ytr_to = 846, 1183, 1211\n",
    "        elif model_no == 4:\n",
    "            xtr_from, xtr_to, ytr_to = 1211, 1548, 1576\n",
    "\n",
    "        xte_from, xte_to = 1604, 1941                                 \n",
    "\n",
    "    if df.id.iloc[0].find('validation') != -1:                       # if validation data\n",
    "        if model_no == 1:\n",
    "            xtr_from, xtr_to, ytr_to = 88, 425, 453\n",
    "        elif model_no == 2:\n",
    "            xtr_from, xtr_to, ytr_to = 453, 790, 818\n",
    "        elif model_no == 3:\n",
    "            xtr_from, xtr_to, ytr_to = 818, 1155, 1183\n",
    "        elif model_no == 4:\n",
    "            xtr_from, xtr_to, ytr_to = 1183, 1520, 1548\n",
    "\n",
    "        xte_from, xte_to = 1576, 1913                                  \n",
    "        \n",
    "    X_train, y_train = dept_df.iloc[:, xtr_from:xtr_to], dept_df.iloc[:, xtr_to:ytr_to]\n",
    "    X_test = dept_df.iloc[:, xte_from:xte_to]\n",
    "    \n",
    "    X_train, y_train, X_test = np.matrix(X_train).astype(np.float32), np.matrix(y_train).astype(np.float32),\\\n",
    "                               np.matrix(X_test).astype(np.float32)\n",
    "    \n",
    "    X_train, y_train = tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)\n",
    "    X_test = tf.convert_to_tensor(X_test)\n",
    "    \n",
    "    X_train = tf.reshape(X_train, shape = (X_train.shape[0], X_train.shape[1], n_features))\n",
    "    y_train = tf.reshape(y_train, shape = (y_train.shape[0], y_train.shape[1], n_features))\n",
    "    X_test = tf.reshape(X_train, shape = (X_train.shape[0], X_train.shape[1], n_features))\n",
    "    \n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "def fit_and_predict(X_train, y_train, X_test, model, epoch_no):\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    model.fit(X_train, y_train, epochs=epoch_no, verbose=1, callbacks = [terminate_on_acc])\n",
    "    print('Just making the predictions...')\n",
    "    return model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NN(df, dept_id, epoch_no, model):    \n",
    "    \n",
    "    dept_df = df[df.dept_id == dept_id]\n",
    "    print('Working on Dept ', dept_id, 'Total rows to process ', len(dept_df))\n",
    "    \n",
    "    id_col = list(dept_df['id'])                       # we preserve the id_col to recreate the output later\n",
    "    dept_df = dept_df.drop(['id','item_id','dept_id','cat_id','store_id','state_id'], 1)\n",
    "    \n",
    "    print('############################## Fitting and Predicting Model 1 ##############################')\n",
    "    X_train, y_train, X_test = get_train_test(df, dept_df, 1)\n",
    "    y_hat = fit_and_predict(X_train, y_train, X_test, model, epoch_no)\n",
    "    print('')\n",
    "\n",
    "    print('############################## Fitting and Predicting Model 2 ##############################')\n",
    "    X_train, y_train, X_test = get_train_test(df, dept_df, 2)\n",
    "    y_hat += fit_and_predict(X_train, y_train, X_test, model, epoch_no)\n",
    "    print('')\n",
    "\n",
    "    print('############################## Fitting and Predicting Model 3 ##############################')\n",
    "    X_train, y_train, X_test = get_train_test(df, dept_df, 3)\n",
    "    y_hat += fit_and_predict(X_train, y_train, X_test, model, epoch_no)\n",
    "    print('')\n",
    "\n",
    "    print('############################## Fitting and Predicting Model 4 ##############################')\n",
    "    X_train, y_train, X_test = get_train_test(df, dept_df, 4)\n",
    "    y_hat += fit_and_predict(X_train, y_train, X_test, model, epoch_no)\n",
    "    print('')\n",
    "    \n",
    "    out_df = pd.DataFrame(y_hat/4)\n",
    "    \n",
    "    l = []                                              # In this part we rename the columns to F_1, F_2 ....\n",
    "    for i in range(1,29):\n",
    "        l.append('F'+str(i))\n",
    "    out_df.columns = l\n",
    "    out_df['id'] = id_col\n",
    "    \n",
    "    cols = list(out_df)                                           \n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    out_df = out_df[cols]\n",
    "    \n",
    "    print('Writing output...')\n",
    "    print('Done.')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sales_train_evaluation.csv')\n",
    "dept_list = list(set(df.dept_id))\n",
    "dept_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loss = 4    \n",
    "\n",
    "model = Sequential()        \n",
    "model.add(LSTM(5, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(2, activation='relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOBBIES_1 Total rows to process  4160\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 4160 samples\n",
      "Epoch 1/5\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 3.8311\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 4160 samples\n",
      "Epoch 1/5\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 5.1933\n",
      "Epoch 2/5\n",
      "4160/4160 [==============================] - 69s 17ms/sample - loss: 5.1943\n",
      "Epoch 3/5\n",
      "4160/4160 [==============================] - 69s 17ms/sample - loss: 5.1604\n",
      "Epoch 4/5\n",
      "4160/4160 [==============================] - 70s 17ms/sample - loss: 5.2051\n",
      "Epoch 5/5\n",
      "4160/4160 [==============================] - 69s 17ms/sample - loss: 5.2102\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 4160 samples\n",
      "Epoch 1/5\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 4.3233\n",
      "Epoch 2/5\n",
      "4160/4160 [==============================] - 70s 17ms/sample - loss: 3.9591\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 4160 samples\n",
      "Epoch 1/5\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 4.4872\n",
      "Epoch 2/5\n",
      "4160/4160 [==============================] - 69s 17ms/sample - loss: 4.5318\n",
      "Epoch 3/5\n",
      "4160/4160 [==============================] - 70s 17ms/sample - loss: 4.2246\n",
      "Epoch 4/5\n",
      "4160/4160 [==============================] - 69s 17ms/sample - loss: 4.1488\n",
      "Epoch 5/5\n",
      "4160/4160 [==============================] - 70s 17ms/sample - loss: 4.0870\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOBBIES_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOBBIES_2 Total rows to process  1490\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 1490 samples\n",
      "Epoch 1/5\n",
      "1490/1490 [==============================] - 28s 19ms/sample - loss: 0.4738\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 1490 samples\n",
      "Epoch 1/5\n",
      "1490/1490 [==============================] - 29s 19ms/sample - loss: 0.6237\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 1490 samples\n",
      "Epoch 1/5\n",
      "1490/1490 [==============================] - 28s 19ms/sample - loss: 0.3922\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 1490 samples\n",
      "Epoch 1/5\n",
      "1490/1490 [==============================] - 28s 19ms/sample - loss: 0.6521\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOBBIES_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOUSEHOLD_1 Total rows to process  5320\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 5320 samples\n",
      "Epoch 1/5\n",
      "5320/5320 [==============================] - 93s 18ms/sample - loss: 2.3560\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 5320 samples\n",
      "Epoch 1/5\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 6.1160\n",
      "Epoch 2/5\n",
      "5320/5320 [==============================] - 93s 17ms/sample - loss: 5.9508\n",
      "Epoch 3/5\n",
      "5320/5320 [==============================] - 92s 17ms/sample - loss: 5.7914\n",
      "Epoch 4/5\n",
      "5320/5320 [==============================] - 93s 17ms/sample - loss: 5.0732\n",
      "Epoch 5/5\n",
      "5320/5320 [==============================] - 93s 17ms/sample - loss: 4.5021\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 5320 samples\n",
      "Epoch 1/5\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 3.0552\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 5320 samples\n",
      "Epoch 1/5\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 3.4420\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOUSEHOLD_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOUSEHOLD_2 Total rows to process  5150\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 5150 samples\n",
      "Epoch 1/5\n",
      "5150/5150 [==============================] - 91s 18ms/sample - loss: 0.4062\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 5150 samples\n",
      "Epoch 1/5\n",
      "5150/5150 [==============================] - 92s 18ms/sample - loss: 0.4677\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 5150 samples\n",
      "Epoch 1/5\n",
      "5150/5150 [==============================] - 91s 18ms/sample - loss: 0.5204\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 5150 samples\n",
      "Epoch 1/5\n",
      "5150/5150 [==============================] - 91s 18ms/sample - loss: 0.5606\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOUSEHOLD_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  FOODS_1 Total rows to process  2160\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 2160 samples\n",
      "Epoch 1/5\n",
      "2160/2160 [==============================] - 41s 19ms/sample - loss: 11.6433\n",
      "Epoch 2/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 7.6292\n",
      "Epoch 3/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 5.8089\n",
      "Epoch 4/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 5.5550\n",
      "Epoch 5/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 5.4254\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 2160 samples\n",
      "Epoch 1/5\n",
      "2160/2160 [==============================] - 40s 19ms/sample - loss: 6.0332\n",
      "Epoch 2/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 5.8647\n",
      "Epoch 3/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 5.8448\n",
      "Epoch 4/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 5.6958\n",
      "Epoch 5/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 5.6661\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 2160 samples\n",
      "Epoch 1/5\n",
      "2160/2160 [==============================] - 40s 19ms/sample - loss: 3.7279\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 2160 samples\n",
      "Epoch 1/5\n",
      "2160/2160 [==============================] - 40s 19ms/sample - loss: 5.1544\n",
      "Epoch 2/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 5.0377\n",
      "Epoch 3/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 4.9466\n",
      "Epoch 4/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 4.9827\n",
      "Epoch 5/5\n",
      "2160/2160 [==============================] - 38s 18ms/sample - loss: 4.9115\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'FOODS_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  FOODS_2 Total rows to process  3980\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 3980 samples\n",
      "Epoch 1/5\n",
      "3980/3980 [==============================] - 72s 18ms/sample - loss: 2.6118\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 3980 samples\n",
      "Epoch 1/5\n",
      "3980/3980 [==============================] - 72s 18ms/sample - loss: 3.3086\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 3980 samples\n",
      "Epoch 1/5\n",
      "3980/3980 [==============================] - 72s 18ms/sample - loss: 2.7808\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 3980 samples\n",
      "Epoch 1/5\n",
      "3980/3980 [==============================] - 73s 18ms/sample - loss: 2.8437\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'FOODS_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_name_to_train = 'FOODS_3'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 8, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HOBBIES_2',\n",
       " 'HOUSEHOLD_1',\n",
       " 'FOODS_2',\n",
       " 'FOODS_1',\n",
       " 'FOODS_3',\n",
       " 'HOUSEHOLD_2',\n",
       " 'HOBBIES_1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sales_train_validation.csv')\n",
    "dept_list = list(set(df.dept_id))\n",
    "dept_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loss = 4    \n",
    "\n",
    "model = Sequential()        \n",
    "model.add(LSTM(5, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(2, activation='relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOBBIES_1 Total rows to process  4160\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 4160 samples\n",
      "Epoch 1/5\n",
      "4160/4160 [==============================] - 86s 21ms/sample - loss: 5.8809\n",
      "Epoch 2/5\n",
      "4160/4160 [==============================] - 77s 19ms/sample - loss: 5.7183\n",
      "Epoch 3/5\n",
      "4160/4160 [==============================] - 78s 19ms/sample - loss: 5.7148\n",
      "Epoch 4/5\n",
      "4160/4160 [==============================] - 78s 19ms/sample - loss: 5.7158\n",
      "Epoch 5/5\n",
      "4160/4160 [==============================] - 78s 19ms/sample - loss: 5.7175\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 4160 samples\n",
      "Epoch 1/5\n",
      "4160/4160 [==============================] - 79s 19ms/sample - loss: 6.1390\n",
      "Epoch 2/5\n",
      "4160/4160 [==============================] - 76s 18ms/sample - loss: 6.1354\n",
      "Epoch 3/5\n",
      "4160/4160 [==============================] - 77s 18ms/sample - loss: 6.1340\n",
      "Epoch 4/5\n",
      "4160/4160 [==============================] - 76s 18ms/sample - loss: 6.1352\n",
      "Epoch 5/5\n",
      "4160/4160 [==============================] - 76s 18ms/sample - loss: 6.1357\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 4160 samples\n",
      "Epoch 1/5\n",
      "4160/4160 [==============================] - 80s 19ms/sample - loss: 4.7331\n",
      "Epoch 2/5\n",
      "4160/4160 [==============================] - 77s 19ms/sample - loss: 4.7270\n",
      "Epoch 3/5\n",
      "4160/4160 [==============================] - 78s 19ms/sample - loss: 4.7297\n",
      "Epoch 4/5\n",
      "4160/4160 [==============================] - 77s 19ms/sample - loss: 4.7293\n",
      "Epoch 5/5\n",
      "4160/4160 [==============================] - 77s 19ms/sample - loss: 4.7279\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 4160 samples\n",
      "Epoch 1/5\n",
      "4160/4160 [==============================] - 80s 19ms/sample - loss: 5.5501\n",
      "Epoch 2/5\n",
      "4160/4160 [==============================] - 77s 19ms/sample - loss: 5.5470\n",
      "Epoch 3/5\n",
      "4160/4160 [==============================] - 77s 18ms/sample - loss: 5.5474\n",
      "Epoch 4/5\n",
      "4160/4160 [==============================] - 78s 19ms/sample - loss: 5.5486\n",
      "Epoch 5/5\n",
      "4160/4160 [==============================] - 77s 19ms/sample - loss: 5.5479\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOBBIES_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOBBIES_2 Total rows to process  1490\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 1490 samples\n",
      "Epoch 1/5\n",
      "1490/1490 [==============================] - 31s 21ms/sample - loss: 0.5565\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 1490 samples\n",
      "Epoch 1/5\n",
      "1490/1490 [==============================] - 30s 20ms/sample - loss: 0.4748\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 1490 samples\n",
      "Epoch 1/5\n",
      "1490/1490 [==============================] - 31s 21ms/sample - loss: 0.3713\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 1490 samples\n",
      "Epoch 1/5\n",
      "1490/1490 [==============================] - 31s 21ms/sample - loss: 0.7652\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOBBIES_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOUSEHOLD_1 Total rows to process  5320\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 5320 samples\n",
      "Epoch 1/5\n",
      "5320/5320 [==============================] - 104s 20ms/sample - loss: 4.8621\n",
      "Epoch 2/5\n",
      "5320/5320 [==============================] - 100s 19ms/sample - loss: 4.8227\n",
      "Epoch 3/5\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 4.8213\n",
      "Epoch 4/5\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 4.8205\n",
      "Epoch 5/5\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 4.8185\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 5320 samples\n",
      "Epoch 1/5\n",
      "5320/5320 [==============================] - 98s 18ms/sample - loss: 13.2893\n",
      "Epoch 2/5\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 13.2466\n",
      "Epoch 3/5\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 13.2472\n",
      "Epoch 4/5\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 13.2448\n",
      "Epoch 5/5\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 13.2491\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 5320 samples\n",
      "Epoch 1/5\n",
      "5320/5320 [==============================] - 100s 19ms/sample - loss: 8.5981\n",
      "Epoch 2/5\n",
      "5320/5320 [==============================] - 98s 18ms/sample - loss: 8.5883\n",
      "Epoch 3/5\n",
      "5320/5320 [==============================] - 97s 18ms/sample - loss: 8.5957\n",
      "Epoch 4/5\n",
      "5320/5320 [==============================] - 97s 18ms/sample - loss: 8.5917\n",
      "Epoch 5/5\n",
      "5320/5320 [==============================] - 97s 18ms/sample - loss: 8.5932\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 5320 samples\n",
      "Epoch 1/5\n",
      "5320/5320 [==============================] - 99s 19ms/sample - loss: 7.6924\n",
      "Epoch 2/5\n",
      "5320/5320 [==============================] - 97s 18ms/sample - loss: 7.6831\n",
      "Epoch 3/5\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 7.6821\n",
      "Epoch 4/5\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 7.6868\n",
      "Epoch 5/5\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 7.6797\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOUSEHOLD_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOUSEHOLD_2 Total rows to process  5150\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 5150 samples\n",
      "Epoch 1/5\n",
      "5150/5150 [==============================] - 94s 18ms/sample - loss: 0.7103\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 5150 samples\n",
      "Epoch 1/5\n",
      "5150/5150 [==============================] - 96s 19ms/sample - loss: 0.6427\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 5150 samples\n",
      "Epoch 1/5\n",
      "5150/5150 [==============================] - 99s 19ms/sample - loss: 0.6978\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 4 ##############################\n",
      "Train on 5150 samples\n",
      "Epoch 1/5\n",
      "5150/5150 [==============================] - 94s 18ms/sample - loss: 0.8399\n",
      "Just making the predictions...\n",
      "\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOUSEHOLD_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  FOODS_1 Total rows to process  2160\n",
      "############################## Fitting and Predicting Model 1 ##############################\n",
      "Train on 2160 samples\n",
      "Epoch 1/5\n",
      "2160/2160 [==============================] - 42s 19ms/sample - loss: 14.3331\n",
      "Epoch 2/5\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 13.9233\n",
      "Epoch 3/5\n",
      "2160/2160 [==============================] - 40s 18ms/sample - loss: 13.8894\n",
      "Epoch 4/5\n",
      "2160/2160 [==============================] - 40s 18ms/sample - loss: 13.8783\n",
      "Epoch 5/5\n",
      "2160/2160 [==============================] - 40s 19ms/sample - loss: 13.8816\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 2 ##############################\n",
      "Train on 2160 samples\n",
      "Epoch 1/5\n",
      "2160/2160 [==============================] - 42s 20ms/sample - loss: 10.5041\n",
      "Epoch 2/5\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 10.4502\n",
      "Epoch 3/5\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 10.4463\n",
      "Epoch 4/5\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 10.4389\n",
      "Epoch 5/5\n",
      "2160/2160 [==============================] - 40s 18ms/sample - loss: 10.4377\n",
      "Just making the predictions...\n",
      "\n",
      "############################## Fitting and Predicting Model 3 ##############################\n",
      "Train on 2160 samples\n",
      "Epoch 1/5\n",
      "2160/2160 [==============================] - 42s 19ms/sample - loss: 10.3577\n",
      "Epoch 2/5\n",
      "1216/2160 [===============>..............] - ETA: 16s - loss: 11.1893"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'FOODS_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_name_to_train = 'FOODS_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 5, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dept_name_to_train = 'FOODS_3'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m5_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging outputs for all departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(name):\n",
    "    return pd.read_csv(name+'.csv')\n",
    "\n",
    "food1ev, food2ev, food3ev = fun('FOODS_1_m5_ev'), fun('FOODS_2_m5_ev'), fun('FOODS_3_m5_ev')\n",
    "hobbies1ev, hobbies2ev = fun('HOBBIES_1_m5_ev'), fun('HOBBIES_2_m5_ev')\n",
    "house1ev, house2ev = fun('HOUSEHOLD_1_m5_ev'), fun('HOUSEHOLD_2_m5_ev')\n",
    "\n",
    "food1val, food2val, food3val = fun('FOODS_1_m5_val'), fun('FOODS_2_m5_val'), fun('FOODS_3_m5_val')\n",
    "hobbies1val, hobbies2val = fun('HOBBIES_1_m5_val'), fun('HOBBIES_2_m5_val')\n",
    "house1val, house2val = fun('HOUSEHOLD_1_m5_val'), fun('HOUSEHOLD_2_m5_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_out_df_ev = pd.concat([food1ev, food2ev, food3ev, hobbies1ev, hobbies2ev, house1ev, house2ev], \n",
    "                           ignore_index=False)\n",
    "main_out_df_val = pd.concat([food1val, food2val, food3val, hobbies1val, hobbies2val, house1val, house2val],\n",
    "                            ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df, main_out):\n",
    "    df['sp_index'] = (df.index)\n",
    "    index_dict = dict(zip(df.id, df.sp_index))\n",
    "    df = df.drop('sp_index', axis=1)\n",
    "    main_out['sp_index'] = main_out[\"id\"].map(index_dict)\n",
    "    main_out = main_out.sort_values(by='sp_index', axis=0)\n",
    "    main_out = main_out.drop('sp_index', axis=1)\n",
    "    return main_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = reorder(pd.read_csv('sales_train_evaluation.csv'), main_out_df_ev)\n",
    "out_2 = reorder(pd.read_csv('sales_train_validation.csv'), main_out_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([out_1, out_2], ignore_index=False)\n",
    "df.to_csv('submissible_nn_M5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)\n",
    "df.to_csv('submissible_nn_M5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.77</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.53</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.63</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.52</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1.49</td>\n",
       "      <td>1.29</td>\n",
       "      <td>1.53</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.02</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8225</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8226</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8227</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8228</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>2.19</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.04</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.99</td>\n",
       "      <td>2.24</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.42</td>\n",
       "      <td>2.63</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>1.86</td>\n",
       "      <td>2.01</td>\n",
       "      <td>2.30</td>\n",
       "      <td>2.22</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60980 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id    F1    F2    F3    F4    F5    F6    F7  \\\n",
       "0     HOBBIES_1_001_CA_1_evaluation  0.59  0.54  0.57  0.48  0.43  0.55  0.57   \n",
       "1     HOBBIES_1_002_CA_1_evaluation  0.53  0.54  0.54  0.43  0.38  0.44  0.44   \n",
       "2     HOBBIES_1_003_CA_1_evaluation  0.45  0.43  0.49  0.38  0.33  0.40  0.41   \n",
       "3     HOBBIES_1_004_CA_1_evaluation  1.65  1.40  1.31  1.30  1.22  1.61  1.77   \n",
       "4     HOBBIES_1_005_CA_1_evaluation  0.98  0.95  0.83  0.72  0.67  0.85  0.90   \n",
       "...                             ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "8225    FOODS_3_823_WI_3_validation  2.19  2.33  2.04  2.11  1.99  2.24  2.14   \n",
       "8226    FOODS_3_824_WI_3_validation  2.19  2.33  2.04  2.11  1.99  2.24  2.14   \n",
       "8227    FOODS_3_825_WI_3_validation  2.19  2.33  2.04  2.11  1.99  2.24  2.14   \n",
       "8228    FOODS_3_826_WI_3_validation  2.19  2.33  2.04  2.11  1.99  2.24  2.14   \n",
       "8229    FOODS_3_827_WI_3_validation  2.19  2.33  2.04  2.11  1.99  2.24  2.14   \n",
       "\n",
       "        F8    F9  ...   F19   F20   F21   F22   F23   F24   F25   F26   F27  \\\n",
       "0     0.58  0.62  ...  0.47  0.52  0.55  0.56  0.55  0.52  0.49  0.45  0.52   \n",
       "1     0.50  0.53  ...  0.50  0.52  0.53  0.53  0.59  0.55  0.52  0.45  0.49   \n",
       "2     0.45  0.49  ...  0.38  0.40  0.40  0.41  0.44  0.41  0.38  0.34  0.38   \n",
       "3     1.70  1.53  ...  1.34  1.45  1.63  1.81  1.52  1.43  1.49  1.29  1.53   \n",
       "4     0.95  0.89  ...  0.90  0.96  1.02  1.05  1.04  0.97  0.97  0.86  0.96   \n",
       "...    ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "8225  2.42  2.63  ...  1.88  1.86  2.01  2.30  2.22  2.15  1.96  1.74  1.78   \n",
       "8226  2.42  2.63  ...  1.88  1.86  2.01  2.30  2.22  2.15  1.96  1.74  1.78   \n",
       "8227  2.42  2.63  ...  1.88  1.86  2.01  2.30  2.22  2.15  1.96  1.74  1.78   \n",
       "8228  2.42  2.63  ...  1.88  1.86  2.01  2.30  2.22  2.15  1.96  1.74  1.78   \n",
       "8229  2.42  2.63  ...  1.88  1.86  2.01  2.30  2.22  2.15  1.96  1.74  1.78   \n",
       "\n",
       "       F28  \n",
       "0     0.53  \n",
       "1     0.46  \n",
       "2     0.36  \n",
       "3     1.78  \n",
       "4     1.03  \n",
       "...    ...  \n",
       "8225  1.93  \n",
       "8226  1.93  \n",
       "8227  1.93  \n",
       "8228  1.93  \n",
       "8229  1.93  \n",
       "\n",
       "[60980 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
