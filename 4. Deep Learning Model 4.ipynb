{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Deep Learning Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First score is Private and second score is Public score"
   ]
  },
  {
   "attachments": {
    "Screenshot%20-%2014-11-2020%20,%2012_07_17.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot%20-%2014-11-2020%20,%2012_07_17.png](attachment:Screenshot%20-%2014-11-2020%20,%2012_07_17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip m5-forecasting-accuracy.zip\n",
    "\n",
    "# !apt-get update\n",
    "# !apt-get install wget\n",
    "\n",
    "# ! pip install pandas\n",
    "# ! pip install calender\n",
    "# ! pip install numpy\n",
    "# ! pip install datetime\n",
    "# ! pip install matplotlib\n",
    "# ! pip install collections\n",
    "# ! pip install random\n",
    "# ! pip install tqdm\n",
    "# ! pip install sklearn\n",
    "# ! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/18599/1236839/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1605098805&Signature=mxKXOkRvWTFe4iO0qjeG%2FYaSe60c9c5Rzd4t30F0ppuxk0%2FfjymTXorLhuRBOWi60l3%2F1AFhnLBXlU1%2BL5wLP6Tf0Lv9MWnpg2WZ00Ugfz19v91Orp1CpnbFmkNo0fh04R4rA%2Fd7%2FOJ6%2Bc6qLPQDdCnbvWSxlMpSerZ0Hx5U9suwh%2FBXuZSjiTeGggdNmeAO0tsIRAz%2BBQ1jE1KQEkCLwfXVr%2BaMPh%2Bi57Q5FiPS6OfdhoO%2BP1a2%2FFdDarIzKe8Ga6Ay2vTjHGzPsDJ7wdmtIpxVyaIcy0iSnkGJJ30ok0JowHFZ50NOqZcf3atRKJJiG%2FKulIObtnL6HLRjc%2B4X2Q%3D%3D&response-content-disposition=attachment%3B+filename%3Dm5-forecasting-accuracy.zip\" -c -O 'm5-forecasting-accuracy.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import activations\n",
    "from IPython.display import clear_output as cclear\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class terminate_on_acc(tf.keras.callbacks.Callback):    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs['loss']\n",
    "        if loss < target_loss:\n",
    "            self.model.stop_training = True\n",
    "terminate_on_acc = terminate_on_acc()\n",
    "\n",
    "n_steps_in, n_steps_out = 365, 28              # input is 1885 days, output 28 days\n",
    "n_features = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval 0---------1885-----1913-----1941------1969\n",
    "#          1548-----------1913-----1941------1969\n",
    "#          -------xtrain---.--ytrain---\n",
    "#              (1548-1913)  (1913-1941)\n",
    "#            ------------xtest---------\n",
    "#                     (1520-1941)\n",
    "            \n",
    "# val  0---------1885-----1913\n",
    "#            1548-----------1913\n",
    "#            xtrain-----.ytrain-\n",
    "#   (1548 to (1913-28))   ((1913-28) to 1913)\n",
    "#            -------xtest-------\n",
    "#           ((1913-365) to 1913)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_NN(df, dept_id, epoch_no, model):    \n",
    "    \n",
    "    dept_df = df[df.dept_id == dept_id]\n",
    "    print('Working on Dept ', dept_id, 'Total rows to process ', len(dept_df))\n",
    "    \n",
    "    id_col = list(dept_df['id'])                                     # we preserve the id_col to recreate the output later\n",
    "    dept_df = dept_df.drop(['id','item_id','dept_id','cat_id','store_id','state_id'], 1)\n",
    "\n",
    "    \n",
    "    if df.id.iloc[0].find('evaluation') != -1:                       # if evaluation data\n",
    "        xtr_from, xtr_to, ytr_to = 1913-365, 1913, 1941                    \n",
    "        xte_from, xte_to = 1941-365, 1941                                  \n",
    "        checkpoint = ModelCheckpoint(filepath='model_'+str(dept_id)+'_m4_ev.h5',\n",
    "                                     monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    if df.id.iloc[0].find('validation') != -1:                       # if validation data\n",
    "        xtr_from, xtr_to, ytr_to = 1913-365, 1913-28, 1913                 \n",
    "        xte_from, xte_to = 1913-365, 1913                                  \n",
    "        checkpoint = ModelCheckpoint(filepath='model_'+str(dept_id)+'_m4_val.h5',\n",
    "                                     monitor='loss', verbose=1, save_best_only=True, mode='auto')\n",
    "    \n",
    "    \n",
    "    X_train, y_train = dept_df.iloc[:, xtr_from:xtr_to], dept_df.iloc[:, xtr_to:ytr_to]\n",
    "    X_test = dept_df.iloc[:, xte_from:xte_to]    \n",
    "    \n",
    "    X_train, y_train, X_test = np.matrix(X_train).astype(np.float32), np.matrix(y_train).astype(np.float32),\\\n",
    "                               np.matrix(X_test).astype(np.float32)\n",
    "    \n",
    "    X_train, y_train = tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)\n",
    "    X_test = tf.convert_to_tensor(X_test)\n",
    "    \n",
    "    X_train = tf.reshape(X_train, shape = (X_train.shape[0], X_train.shape[1], n_features))\n",
    "    y_train = tf.reshape(y_train, shape = (y_train.shape[0], y_train.shape[1], n_features))\n",
    "    X_test = tf.reshape(X_train, shape = (X_train.shape[0], X_train.shape[1], n_features))\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=epoch_no, verbose=1, callbacks = [terminate_on_acc, checkpoint])\n",
    "    \n",
    "    print('Predicting...')\n",
    "    y_hat = model.predict(X_test)\n",
    "    \n",
    "    out_df = pd.DataFrame(y_hat)\n",
    "    l = []                                              # In this part we rename the columns to F_1, F_2 ....\n",
    "    for i in range(1,29):\n",
    "        l.append('F'+str(i))\n",
    "    out_df.columns = l\n",
    "    out_df['id'] = id_col\n",
    "    \n",
    "    cols = list(out_df)                                           \n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    out_df = out_df[cols]\n",
    "    \n",
    "    print('Writing output...')\n",
    "    print('Done.')\n",
    "    return out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HOBBIES_1',\n",
       " 'HOUSEHOLD_1',\n",
       " 'HOBBIES_2',\n",
       " 'FOODS_2',\n",
       " 'FOODS_1',\n",
       " 'FOODS_3',\n",
       " 'HOUSEHOLD_2']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sales_train_evaluation.csv')\n",
    "dept_list = list(set(df.dept_id))\n",
    "dept_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loss = 4    \n",
    "\n",
    "model = Sequential()        \n",
    "model.add(LSTM(5, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(2, activation='relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOBBIES_1 Total rows to process  4160\n",
      "Train on 4160 samples\n",
      "Epoch 1/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.7405\n",
      "Epoch 00001: loss improved from inf to 5.70960, saving model to model_HOBBIES_1_ev.h5\n",
      "4160/4160 [==============================] - 74s 18ms/sample - loss: 5.7096\n",
      "Epoch 2/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.7875\n",
      "Epoch 00002: loss did not improve from 5.70960\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 5.7978\n",
      "Epoch 3/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.2912\n",
      "Epoch 00003: loss improved from 5.70960 to 5.26808, saving model to model_HOBBIES_1_ev.h5\n",
      "4160/4160 [==============================] - 73s 18ms/sample - loss: 5.2681\n",
      "Epoch 4/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.2787\n",
      "Epoch 00004: loss improved from 5.26808 to 5.26386, saving model to model_HOBBIES_1_ev.h5\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 5.2639\n",
      "Epoch 5/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.2705\n",
      "Epoch 00005: loss improved from 5.26386 to 5.26270, saving model to model_HOBBIES_1_ev.h5\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 5.2627\n",
      "Epoch 6/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.2649\n",
      "Epoch 00006: loss did not improve from 5.26270\n",
      "4160/4160 [==============================] - 73s 17ms/sample - loss: 5.2628\n",
      "Epoch 7/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.2731\n",
      "Epoch 00007: loss improved from 5.26270 to 5.26202, saving model to model_HOBBIES_1_ev.h5\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 5.2620\n",
      "Epoch 8/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.2956\n",
      "Epoch 00008: loss did not improve from 5.26202\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 5.2626\n",
      "Epoch 9/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.2905\n",
      "Epoch 00009: loss did not improve from 5.26202\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 5.2631\n",
      "Epoch 10/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 5.2830\n",
      "Epoch 00010: loss did not improve from 5.26202\n",
      "4160/4160 [==============================] - 72s 17ms/sample - loss: 5.2641\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOBBIES_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOBBIES_2 Total rows to process  1490\n",
      "Train on 1490 samples\n",
      "Epoch 1/10\n",
      "1472/1490 [============================>.] - ETA: 0s - loss: 0.8943\n",
      "Epoch 00001: loss improved from inf to 0.89034, saving model to model_HOBBIES_2_ev.h5\n",
      "1490/1490 [==============================] - 29s 19ms/sample - loss: 0.8903\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOBBIES_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  FOODS_1 Total rows to process  2160\n",
      "Train on 2160 samples\n",
      "Epoch 1/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 12.5742\n",
      "Epoch 00001: loss improved from inf to 12.50411, saving model to model_FOODS_1_ev.h5\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 12.5041\n",
      "Epoch 2/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 11.9722\n",
      "Epoch 00002: loss improved from 12.50411 to 11.91743, saving model to model_FOODS_1_ev.h5\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 11.9174\n",
      "Epoch 3/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 11.8707\n",
      "Epoch 00003: loss did not improve from 11.91743\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 11.9190\n",
      "Epoch 4/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 11.9844\n",
      "Epoch 00004: loss improved from 11.91743 to 11.91687, saving model to model_FOODS_1_ev.h5\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 11.9169\n",
      "Epoch 5/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 11.8518\n",
      "Epoch 00005: loss did not improve from 11.91687\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 11.9194\n",
      "Epoch 6/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 11.9564\n",
      "Epoch 00006: loss did not improve from 11.91687\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 11.9171\n",
      "Epoch 7/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 11.9527\n",
      "Epoch 00007: loss improved from 11.91687 to 11.91536, saving model to model_FOODS_1_ev.h5\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 11.9154\n",
      "Epoch 8/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 11.9982\n",
      "Epoch 00008: loss did not improve from 11.91536\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 11.9282\n",
      "Epoch 9/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 11.7909\n",
      "Epoch 00009: loss did not improve from 11.91536\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 11.9209\n",
      "Epoch 10/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 11.9274\n",
      "Epoch 00010: loss did not improve from 11.91536\n",
      "2160/2160 [==============================] - 39s 18ms/sample - loss: 11.9197\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'FOODS_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  FOODS_2 Total rows to process  3980\n",
      "Train on 3980 samples\n",
      "Epoch 1/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.6081\n",
      "Epoch 00001: loss improved from inf to 8.63587, saving model to model_FOODS_2_ev.h5\n",
      "3980/3980 [==============================] - 71s 18ms/sample - loss: 8.6359\n",
      "Epoch 2/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.6391\n",
      "Epoch 00002: loss improved from 8.63587 to 8.61806, saving model to model_FOODS_2_ev.h5\n",
      "3980/3980 [==============================] - 71s 18ms/sample - loss: 8.6181\n",
      "Epoch 3/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.6353\n",
      "Epoch 00003: loss did not improve from 8.61806\n",
      "3980/3980 [==============================] - 71s 18ms/sample - loss: 8.6194\n",
      "Epoch 4/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.6327\n",
      "Epoch 00004: loss improved from 8.61806 to 8.61600, saving model to model_FOODS_2_ev.h5\n",
      "3980/3980 [==============================] - 71s 18ms/sample - loss: 8.6160\n",
      "Epoch 5/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.6362\n",
      "Epoch 00005: loss did not improve from 8.61600\n",
      "3980/3980 [==============================] - 71s 18ms/sample - loss: 8.6225\n",
      "Epoch 6/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.5822\n",
      "Epoch 00006: loss improved from 8.61600 to 8.61507, saving model to model_FOODS_2_ev.h5\n",
      "3980/3980 [==============================] - 71s 18ms/sample - loss: 8.6151\n",
      "Epoch 7/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.6417\n",
      "Epoch 00007: loss did not improve from 8.61507\n",
      "3980/3980 [==============================] - 71s 18ms/sample - loss: 8.6214\n",
      "Epoch 8/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.6020\n",
      "Epoch 00008: loss did not improve from 8.61507\n",
      "3980/3980 [==============================] - 71s 18ms/sample - loss: 8.6222\n",
      "Epoch 9/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.5981\n",
      "Epoch 00009: loss did not improve from 8.61507\n",
      "3980/3980 [==============================] - 71s 18ms/sample - loss: 8.6192\n",
      "Epoch 10/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 8.6370\n",
      "Epoch 00010: loss did not improve from 8.61507\n",
      "3980/3980 [==============================] - 72s 18ms/sample - loss: 8.6203\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'FOODS_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is possible FOODS_3 needs the data to be broken to years, may be the model is unable to learn all the years\n",
    "# together. We try to break it in Model 5. For now we will use this MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  FOODS_3 Total rows to process  8230\n",
      "Train on 8230 samples\n",
      "Epoch 1/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4986\n",
      "Epoch 00001: loss improved from inf to 31.47969, saving model to model_FOODS_3_ev.h5\n",
      "8230/8230 [==============================] - 147s 18ms/sample - loss: 31.4797\n",
      "Epoch 2/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4326\n",
      "Epoch 00002: loss improved from 31.47969 to 31.41348, saving model to model_FOODS_3_ev.h5\n",
      "8230/8230 [==============================] - 147s 18ms/sample - loss: 31.4135\n",
      "Epoch 3/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4286\n",
      "Epoch 00003: loss improved from 31.41348 to 31.40882, saving model to model_FOODS_3_ev.h5\n",
      "8230/8230 [==============================] - 147s 18ms/sample - loss: 31.4088\n",
      "Epoch 4/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4505\n",
      "Epoch 00004: loss did not improve from 31.40882\n",
      "8230/8230 [==============================] - 147s 18ms/sample - loss: 31.4304\n",
      "Epoch 5/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4312\n",
      "Epoch 00005: loss did not improve from 31.40882\n",
      "8230/8230 [==============================] - 147s 18ms/sample - loss: 31.4113\n",
      "Epoch 6/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4440\n",
      "Epoch 00006: loss did not improve from 31.40882\n",
      "8230/8230 [==============================] - 147s 18ms/sample - loss: 31.4272\n",
      "Epoch 7/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4323\n",
      "Epoch 00007: loss did not improve from 31.40882\n",
      "8230/8230 [==============================] - 147s 18ms/sample - loss: 31.4127\n",
      "Epoch 8/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4373\n",
      "Epoch 00008: loss did not improve from 31.40882\n",
      "8230/8230 [==============================] - 147s 18ms/sample - loss: 31.4180\n",
      "Epoch 9/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4350\n",
      "Epoch 00009: loss did not improve from 31.40882\n",
      "8230/8230 [==============================] - 147s 18ms/sample - loss: 31.4148\n",
      "Epoch 10/10\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 31.4297\n",
      "Epoch 00010: loss did not improve from 31.40882\n",
      "8230/8230 [==============================] - 146s 18ms/sample - loss: 31.4097\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'FOODS_3'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOUSEHOLD_1 Total rows to process  5320\n",
      "Train on 5320 samples\n",
      "Epoch 1/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.3126\n",
      "Epoch 00001: loss improved from inf to 7.32039, saving model to model_HOUSEHOLD_1_ev.h5\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 7.3204\n",
      "Epoch 2/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.2427\n",
      "Epoch 00002: loss improved from 7.32039 to 7.23633, saving model to model_HOUSEHOLD_1_ev.h5\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 7.2363\n",
      "Epoch 3/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.2436\n",
      "Epoch 00003: loss did not improve from 7.23633\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 7.2381\n",
      "Epoch 4/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.2439\n",
      "Epoch 00004: loss did not improve from 7.23633\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 7.2377\n",
      "Epoch 5/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.2453\n",
      "Epoch 00005: loss did not improve from 7.23633\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 7.2391\n",
      "Epoch 6/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.2455\n",
      "Epoch 00006: loss did not improve from 7.23633\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 7.2401\n",
      "Epoch 7/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.2425\n",
      "Epoch 00007: loss did not improve from 7.23633\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 7.2368\n",
      "Epoch 8/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.2459\n",
      "Epoch 00008: loss did not improve from 7.23633\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 7.2379\n",
      "Epoch 9/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.2476\n",
      "Epoch 00009: loss did not improve from 7.23633\n",
      "5320/5320 [==============================] - 96s 18ms/sample - loss: 7.2394\n",
      "Epoch 10/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 7.2463\n",
      "Epoch 00010: loss did not improve from 7.23633\n",
      "5320/5320 [==============================] - 95s 18ms/sample - loss: 7.2395\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOUSEHOLD_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOUSEHOLD_2 Total rows to process  5150\n",
      "Train on 5150 samples\n",
      "Epoch 1/10\n",
      "5120/5150 [============================>.] - ETA: 0s - loss: 1.1632\n",
      "Epoch 00001: loss improved from inf to 1.15916, saving model to model_HOUSEHOLD_2_ev.h5\n",
      "5150/5150 [==============================] - 92s 18ms/sample - loss: 1.1592\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOUSEHOLD_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_ev.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HOBBIES_1',\n",
       " 'HOUSEHOLD_1',\n",
       " 'HOBBIES_2',\n",
       " 'FOODS_2',\n",
       " 'FOODS_1',\n",
       " 'FOODS_3',\n",
       " 'HOUSEHOLD_2']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('sales_train_validation.csv')\n",
    "dept_list = list(set(df.dept_id))\n",
    "dept_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loss = 4 \n",
    "n_steps_in, n_steps_out = 337, 28   \n",
    "\n",
    "model = Sequential()        \n",
    "model.add(LSTM(5, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "model.add(LSTM(2, activation='relu'))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(10))\n",
    "model.add(Dense(n_steps_out))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOBBIES_1 Total rows to process  4160\n",
      "Train on 4160 samples\n",
      "Epoch 1/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 4.8566\n",
      "Epoch 00001: loss improved from inf to 4.86622, saving model to model_HOBBIES_1_val.h5\n",
      "4160/4160 [==============================] - 69s 17ms/sample - loss: 4.8662\n",
      "Epoch 2/10\n",
      "4128/4160 [============================>.] - ETA: 0s - loss: 3.8923\n",
      "Epoch 00002: loss improved from 4.86622 to 3.87189, saving model to model_HOBBIES_1_val.h5\n",
      "4160/4160 [==============================] - 66s 16ms/sample - loss: 3.8719\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOBBIES_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOBBIES_2 Total rows to process  1490\n",
      "Train on 1490 samples\n",
      "Epoch 1/10\n",
      "1472/1490 [============================>.] - ETA: 0s - loss: 0.6285\n",
      "Epoch 00001: loss improved from inf to 0.62627, saving model to model_HOBBIES_2_val.h5\n",
      "1490/1490 [==============================] - 26s 18ms/sample - loss: 0.6263\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOBBIES_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  FOODS_1 Total rows to process  2160\n",
      "Train on 2160 samples\n",
      "Epoch 1/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 6.3352\n",
      "Epoch 00001: loss improved from inf to 6.33056, saving model to model_FOODS_1_val.h5\n",
      "2160/2160 [==============================] - 36s 17ms/sample - loss: 6.3306\n",
      "Epoch 2/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 5.6592\n",
      "Epoch 00002: loss improved from 6.33056 to 5.65905, saving model to model_FOODS_1_val.h5\n",
      "2160/2160 [==============================] - 36s 17ms/sample - loss: 5.6591\n",
      "Epoch 3/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 5.4389\n",
      "Epoch 00003: loss improved from 5.65905 to 5.42793, saving model to model_FOODS_1_val.h5\n",
      "2160/2160 [==============================] - 36s 17ms/sample - loss: 5.4279\n",
      "Epoch 4/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 5.1686\n",
      "Epoch 00004: loss improved from 5.42793 to 5.17323, saving model to model_FOODS_1_val.h5\n",
      "2160/2160 [==============================] - 36s 17ms/sample - loss: 5.1732\n",
      "Epoch 5/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 5.2307\n",
      "Epoch 00005: loss did not improve from 5.17323\n",
      "2160/2160 [==============================] - 36s 17ms/sample - loss: 5.2517\n",
      "Epoch 6/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 4.8745\n",
      "Epoch 00006: loss improved from 5.17323 to 4.87709, saving model to model_FOODS_1_val.h5\n",
      "2160/2160 [==============================] - 36s 17ms/sample - loss: 4.8771\n",
      "Epoch 7/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 4.8926\n",
      "Epoch 00007: loss improved from 4.87709 to 4.86883, saving model to model_FOODS_1_val.h5\n",
      "2160/2160 [==============================] - 37s 17ms/sample - loss: 4.8688\n",
      "Epoch 8/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 4.7570\n",
      "Epoch 00008: loss improved from 4.86883 to 4.75994, saving model to model_FOODS_1_val.h5\n",
      "2160/2160 [==============================] - 37s 17ms/sample - loss: 4.7599\n",
      "Epoch 9/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 4.6592\n",
      "Epoch 00009: loss improved from 4.75994 to 4.63605, saving model to model_FOODS_1_val.h5\n",
      "2160/2160 [==============================] - 36s 17ms/sample - loss: 4.6360\n",
      "Epoch 10/10\n",
      "2144/2160 [============================>.] - ETA: 0s - loss: 4.5571\n",
      "Epoch 00010: loss improved from 4.63605 to 4.54257, saving model to model_FOODS_1_val.h5\n",
      "2160/2160 [==============================] - 36s 17ms/sample - loss: 4.5426\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'FOODS_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  FOODS_2 Total rows to process  3980\n",
      "Train on 3980 samples\n",
      "Epoch 1/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 4.1481\n",
      "Epoch 00001: loss improved from inf to 4.13970, saving model to model_FOODS_2_val.h5\n",
      "3980/3980 [==============================] - 67s 17ms/sample - loss: 4.1397\n",
      "Epoch 2/10\n",
      "3968/3980 [============================>.] - ETA: 0s - loss: 3.7234\n",
      "Epoch 00002: loss improved from 4.13970 to 3.72195, saving model to model_FOODS_2_val.h5\n",
      "3980/3980 [==============================] - 66s 17ms/sample - loss: 3.7220\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'FOODS_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  FOODS_3 Total rows to process  8230\n",
      "Train on 8230 samples\n",
      "Epoch 1/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.1643\n",
      "Epoch 00001: loss improved from inf to 10.15839, saving model to model_FOODS_3_val.h5\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.1584\n",
      "Epoch 2/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 12.8190\n",
      "Epoch 00002: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 138s 17ms/sample - loss: 12.8124\n",
      "Epoch 3/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 11.3975\n",
      "Epoch 00003: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 136s 17ms/sample - loss: 11.3927\n",
      "Epoch 4/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.8027\n",
      "Epoch 00004: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 138s 17ms/sample - loss: 10.8075\n",
      "Epoch 5/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.7885\n",
      "Epoch 00005: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.9830\n",
      "Epoch 6/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 11.1775\n",
      "Epoch 00006: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 136s 17ms/sample - loss: 11.1724\n",
      "Epoch 7/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.7051\n",
      "Epoch 00007: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.6978\n",
      "Epoch 8/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 12.2877\n",
      "Epoch 00008: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 12.2958\n",
      "Epoch 9/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 11.1781\n",
      "Epoch 00009: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 11.1725\n",
      "Epoch 10/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 12.0908\n",
      "Epoch 00010: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 12.0841\n",
      "Epoch 11/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 11.7791\n",
      "Epoch 00011: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 136s 17ms/sample - loss: 11.7726\n",
      "Epoch 12/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.7011\n",
      "Epoch 00012: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.6972\n",
      "Epoch 13/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 11.0745\n",
      "Epoch 00013: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 11.0688\n",
      "Epoch 14/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.7117\n",
      "Epoch 00014: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.7062\n",
      "Epoch 15/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.3768\n",
      "Epoch 00015: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 136s 17ms/sample - loss: 10.3818\n",
      "Epoch 16/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 11.2809\n",
      "Epoch 00016: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 138s 17ms/sample - loss: 11.2739\n",
      "Epoch 17/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.7785\n",
      "Epoch 00017: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 138s 17ms/sample - loss: 10.7732\n",
      "Epoch 18/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.4972\n",
      "Epoch 00018: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.4949\n",
      "Epoch 19/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.9131\n",
      "Epoch 00019: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.9060\n",
      "Epoch 20/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 11.0970\n",
      "Epoch 00020: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 11.0906\n",
      "Epoch 21/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 11.0173\n",
      "Epoch 00021: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 136s 17ms/sample - loss: 11.0101\n",
      "Epoch 22/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 11.8071\n",
      "Epoch 00022: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 138s 17ms/sample - loss: 11.7999\n",
      "Epoch 23/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.5299\n",
      "Epoch 00023: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.5253\n",
      "Epoch 24/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.2521\n",
      "Epoch 00024: loss did not improve from 10.15839\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.2454\n",
      "Epoch 25/25\n",
      "8224/8230 [============================>.] - ETA: 0s - loss: 10.1559\n",
      "Epoch 00025: loss improved from 10.15839 to 10.15064, saving model to model_FOODS_3_val.h5\n",
      "8230/8230 [==============================] - 137s 17ms/sample - loss: 10.1506\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "target_loss = 7\n",
    "dept_name_to_train = 'FOODS_3'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 25, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOUSEHOLD_1 Total rows to process  5320\n",
      "Train on 5320 samples\n",
      "Epoch 1/10\n",
      "5312/5320 [============================>.] - ETA: 0s - loss: 3.8341\n",
      "Epoch 00001: loss improved from inf to 3.83166, saving model to model_HOUSEHOLD_1_val.h5\n",
      "5320/5320 [==============================] - 89s 17ms/sample - loss: 3.8317\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOUSEHOLD_1'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Dept  HOUSEHOLD_2 Total rows to process  5150\n",
      "Train on 5150 samples\n",
      "Epoch 1/10\n",
      "5120/5150 [============================>.] - ETA: 0s - loss: 0.6495\n",
      "Epoch 00001: loss improved from inf to 0.64920, saving model to model_HOUSEHOLD_2_val.h5\n",
      "5150/5150 [==============================] - 85s 17ms/sample - loss: 0.6492\n",
      "Predicting...\n",
      "Writing output...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dept_name_to_train = 'HOUSEHOLD_2'\n",
    "\n",
    "out_df = train_NN(df, dept_name_to_train, 10, model)\n",
    "out_df.to_csv(str(dept_name_to_train)+'_m4_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging outputs for all departments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(name):\n",
    "    return pd.read_csv(name+'.csv')\n",
    "\n",
    "food1ev, food2ev, food3ev = fun('FOODS_1_m4_ev'), fun('FOODS_2_m4_ev'), fun('FOODS_3_m4_ev')\n",
    "hobbies1ev, hobbies2ev = fun('HOBBIES_1_m4_ev'), fun('HOBBIES_2_m4_ev')\n",
    "house1ev, house2ev = fun('HOUSEHOLD_1_m4_ev'), fun('HOUSEHOLD_2_m4_ev')\n",
    "\n",
    "food1val, food2val, food3val = fun('FOODS_1_m4_val'), fun('FOODS_2_m4_val'), fun('FOODS_3_m4_val')\n",
    "hobbies1val, hobbies2val = fun('HOBBIES_1_m4_val'), fun('HOBBIES_2_m4_val')\n",
    "house1val, house2val = fun('HOUSEHOLD_1_m4_val'), fun('HOUSEHOLD_2_m4_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_out_df_ev = pd.concat([food1ev, food2ev, food3ev, hobbies1ev, hobbies2ev, house1ev, house2ev], \n",
    "                           ignore_index=False)\n",
    "main_out_df_val = pd.concat([food1val, food2val, food3val, hobbies1val, hobbies2val, house1val, house2val],\n",
    "                            ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df, main_out):\n",
    "    df['sp_index'] = (df.index)\n",
    "    index_dict = dict(zip(df.id, df.sp_index))\n",
    "    df = df.drop('sp_index', axis=1)\n",
    "    main_out['sp_index'] = main_out[\"id\"].map(index_dict)\n",
    "    main_out = main_out.sort_values(by='sp_index', axis=0)\n",
    "    main_out = main_out.drop('sp_index', axis=1)\n",
    "    return main_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = reorder(pd.read_csv('sales_train_evaluation.csv'), main_out_df_ev)\n",
    "out_2 = reorder(pd.read_csv('sales_train_validation.csv'), main_out_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([out_1, out_2], ignore_index=False)\n",
    "df.to_csv('submissible_nn_m4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>0.797639</td>\n",
       "      <td>0.768310</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.856761</td>\n",
       "      <td>1.100346</td>\n",
       "      <td>1.032933</td>\n",
       "      <td>0.872190</td>\n",
       "      <td>0.927199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>1.046554</td>\n",
       "      <td>1.049505</td>\n",
       "      <td>0.752165</td>\n",
       "      <td>0.740498</td>\n",
       "      <td>0.784890</td>\n",
       "      <td>0.727829</td>\n",
       "      <td>0.891138</td>\n",
       "      <td>1.175545</td>\n",
       "      <td>1.125135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>0.797639</td>\n",
       "      <td>0.768310</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.856761</td>\n",
       "      <td>1.100346</td>\n",
       "      <td>1.032933</td>\n",
       "      <td>0.872190</td>\n",
       "      <td>0.927199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>1.046554</td>\n",
       "      <td>1.049505</td>\n",
       "      <td>0.752165</td>\n",
       "      <td>0.740498</td>\n",
       "      <td>0.784890</td>\n",
       "      <td>0.727829</td>\n",
       "      <td>0.891138</td>\n",
       "      <td>1.175545</td>\n",
       "      <td>1.125135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>0.797639</td>\n",
       "      <td>0.768310</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.856761</td>\n",
       "      <td>1.100346</td>\n",
       "      <td>1.032933</td>\n",
       "      <td>0.872190</td>\n",
       "      <td>0.927199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>1.046554</td>\n",
       "      <td>1.049505</td>\n",
       "      <td>0.752165</td>\n",
       "      <td>0.740498</td>\n",
       "      <td>0.784890</td>\n",
       "      <td>0.727829</td>\n",
       "      <td>0.891138</td>\n",
       "      <td>1.175545</td>\n",
       "      <td>1.125135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>0.797639</td>\n",
       "      <td>0.768310</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.856761</td>\n",
       "      <td>1.100346</td>\n",
       "      <td>1.032933</td>\n",
       "      <td>0.872190</td>\n",
       "      <td>0.927199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>1.046554</td>\n",
       "      <td>1.049505</td>\n",
       "      <td>0.752165</td>\n",
       "      <td>0.740498</td>\n",
       "      <td>0.784890</td>\n",
       "      <td>0.727829</td>\n",
       "      <td>0.891138</td>\n",
       "      <td>1.175545</td>\n",
       "      <td>1.125135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>0.797639</td>\n",
       "      <td>0.768310</td>\n",
       "      <td>0.783257</td>\n",
       "      <td>0.769936</td>\n",
       "      <td>0.856761</td>\n",
       "      <td>1.100346</td>\n",
       "      <td>1.032933</td>\n",
       "      <td>0.872190</td>\n",
       "      <td>0.927199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809794</td>\n",
       "      <td>1.046554</td>\n",
       "      <td>1.049505</td>\n",
       "      <td>0.752165</td>\n",
       "      <td>0.740498</td>\n",
       "      <td>0.784890</td>\n",
       "      <td>0.727829</td>\n",
       "      <td>0.891138</td>\n",
       "      <td>1.175545</td>\n",
       "      <td>1.125135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8225</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.406299</td>\n",
       "      <td>0.353426</td>\n",
       "      <td>0.304667</td>\n",
       "      <td>0.308852</td>\n",
       "      <td>0.403733</td>\n",
       "      <td>0.400387</td>\n",
       "      <td>0.639327</td>\n",
       "      <td>0.503734</td>\n",
       "      <td>0.434844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.359811</td>\n",
       "      <td>0.379057</td>\n",
       "      <td>0.479020</td>\n",
       "      <td>0.457715</td>\n",
       "      <td>0.423304</td>\n",
       "      <td>0.432291</td>\n",
       "      <td>0.442275</td>\n",
       "      <td>0.420320</td>\n",
       "      <td>0.404418</td>\n",
       "      <td>0.643699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8226</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.381522</td>\n",
       "      <td>0.329032</td>\n",
       "      <td>0.280231</td>\n",
       "      <td>0.284648</td>\n",
       "      <td>0.373213</td>\n",
       "      <td>0.362834</td>\n",
       "      <td>0.598375</td>\n",
       "      <td>0.476083</td>\n",
       "      <td>0.405920</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329022</td>\n",
       "      <td>0.343528</td>\n",
       "      <td>0.441265</td>\n",
       "      <td>0.429598</td>\n",
       "      <td>0.397477</td>\n",
       "      <td>0.409173</td>\n",
       "      <td>0.418489</td>\n",
       "      <td>0.392695</td>\n",
       "      <td>0.369446</td>\n",
       "      <td>0.611649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8227</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.896857</td>\n",
       "      <td>0.838457</td>\n",
       "      <td>0.790532</td>\n",
       "      <td>0.795795</td>\n",
       "      <td>1.011501</td>\n",
       "      <td>1.147834</td>\n",
       "      <td>1.451020</td>\n",
       "      <td>1.053665</td>\n",
       "      <td>1.008372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972875</td>\n",
       "      <td>1.086520</td>\n",
       "      <td>1.233734</td>\n",
       "      <td>1.015385</td>\n",
       "      <td>0.939698</td>\n",
       "      <td>0.894035</td>\n",
       "      <td>0.917400</td>\n",
       "      <td>0.972814</td>\n",
       "      <td>1.104909</td>\n",
       "      <td>1.282722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8228</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>1.263219</td>\n",
       "      <td>1.200322</td>\n",
       "      <td>1.153019</td>\n",
       "      <td>1.158073</td>\n",
       "      <td>1.464772</td>\n",
       "      <td>1.705341</td>\n",
       "      <td>2.057056</td>\n",
       "      <td>1.463928</td>\n",
       "      <td>1.436544</td>\n",
       "      <td>...</td>\n",
       "      <td>1.430103</td>\n",
       "      <td>1.614153</td>\n",
       "      <td>1.796083</td>\n",
       "      <td>1.431692</td>\n",
       "      <td>1.324452</td>\n",
       "      <td>1.238158</td>\n",
       "      <td>1.271485</td>\n",
       "      <td>1.384439</td>\n",
       "      <td>1.626607</td>\n",
       "      <td>1.759161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8229</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>2.300390</td>\n",
       "      <td>2.230709</td>\n",
       "      <td>2.185188</td>\n",
       "      <td>2.206030</td>\n",
       "      <td>2.758105</td>\n",
       "      <td>3.295019</td>\n",
       "      <td>3.775285</td>\n",
       "      <td>2.632487</td>\n",
       "      <td>2.651183</td>\n",
       "      <td>...</td>\n",
       "      <td>2.734587</td>\n",
       "      <td>3.119489</td>\n",
       "      <td>3.408958</td>\n",
       "      <td>2.613083</td>\n",
       "      <td>2.428262</td>\n",
       "      <td>2.224005</td>\n",
       "      <td>2.286011</td>\n",
       "      <td>2.565756</td>\n",
       "      <td>3.126914</td>\n",
       "      <td>3.120891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60980 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id        F1        F2        F3        F4  \\\n",
       "0     HOBBIES_1_001_CA_1_evaluation  0.797639  0.768310  0.783257  0.769936   \n",
       "1     HOBBIES_1_002_CA_1_evaluation  0.797639  0.768310  0.783257  0.769936   \n",
       "2     HOBBIES_1_003_CA_1_evaluation  0.797639  0.768310  0.783257  0.769936   \n",
       "3     HOBBIES_1_004_CA_1_evaluation  0.797639  0.768310  0.783257  0.769936   \n",
       "4     HOBBIES_1_005_CA_1_evaluation  0.797639  0.768310  0.783257  0.769936   \n",
       "...                             ...       ...       ...       ...       ...   \n",
       "8225    FOODS_3_823_WI_3_validation  0.406299  0.353426  0.304667  0.308852   \n",
       "8226    FOODS_3_824_WI_3_validation  0.381522  0.329032  0.280231  0.284648   \n",
       "8227    FOODS_3_825_WI_3_validation  0.896857  0.838457  0.790532  0.795795   \n",
       "8228    FOODS_3_826_WI_3_validation  1.263219  1.200322  1.153019  1.158073   \n",
       "8229    FOODS_3_827_WI_3_validation  2.300390  2.230709  2.185188  2.206030   \n",
       "\n",
       "            F5        F6        F7        F8        F9  ...       F19  \\\n",
       "0     0.856761  1.100346  1.032933  0.872190  0.927199  ...  0.809794   \n",
       "1     0.856761  1.100346  1.032933  0.872190  0.927199  ...  0.809794   \n",
       "2     0.856761  1.100346  1.032933  0.872190  0.927199  ...  0.809794   \n",
       "3     0.856761  1.100346  1.032933  0.872190  0.927199  ...  0.809794   \n",
       "4     0.856761  1.100346  1.032933  0.872190  0.927199  ...  0.809794   \n",
       "...        ...       ...       ...       ...       ...  ...       ...   \n",
       "8225  0.403733  0.400387  0.639327  0.503734  0.434844  ...  0.359811   \n",
       "8226  0.373213  0.362834  0.598375  0.476083  0.405920  ...  0.329022   \n",
       "8227  1.011501  1.147834  1.451020  1.053665  1.008372  ...  0.972875   \n",
       "8228  1.464772  1.705341  2.057056  1.463928  1.436544  ...  1.430103   \n",
       "8229  2.758105  3.295019  3.775285  2.632487  2.651183  ...  2.734587   \n",
       "\n",
       "           F20       F21       F22       F23       F24       F25       F26  \\\n",
       "0     1.046554  1.049505  0.752165  0.740498  0.784890  0.727829  0.891138   \n",
       "1     1.046554  1.049505  0.752165  0.740498  0.784890  0.727829  0.891138   \n",
       "2     1.046554  1.049505  0.752165  0.740498  0.784890  0.727829  0.891138   \n",
       "3     1.046554  1.049505  0.752165  0.740498  0.784890  0.727829  0.891138   \n",
       "4     1.046554  1.049505  0.752165  0.740498  0.784890  0.727829  0.891138   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8225  0.379057  0.479020  0.457715  0.423304  0.432291  0.442275  0.420320   \n",
       "8226  0.343528  0.441265  0.429598  0.397477  0.409173  0.418489  0.392695   \n",
       "8227  1.086520  1.233734  1.015385  0.939698  0.894035  0.917400  0.972814   \n",
       "8228  1.614153  1.796083  1.431692  1.324452  1.238158  1.271485  1.384439   \n",
       "8229  3.119489  3.408958  2.613083  2.428262  2.224005  2.286011  2.565756   \n",
       "\n",
       "           F27       F28  \n",
       "0     1.175545  1.125135  \n",
       "1     1.175545  1.125135  \n",
       "2     1.175545  1.125135  \n",
       "3     1.175545  1.125135  \n",
       "4     1.175545  1.125135  \n",
       "...        ...       ...  \n",
       "8225  0.404418  0.643699  \n",
       "8226  0.369446  0.611649  \n",
       "8227  1.104909  1.282722  \n",
       "8228  1.626607  1.759161  \n",
       "8229  3.126914  3.120891  \n",
       "\n",
       "[60980 rows x 29 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)\n",
    "df.to_csv('submissible_nn_m4.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
