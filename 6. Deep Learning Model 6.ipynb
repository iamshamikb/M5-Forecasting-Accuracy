{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New\n",
    "# Models and scores\n",
    "# Total no of submissions this competition has got is 5558\n",
    "#           Private   Public   Private_Rank   In_top%\n",
    "# ML models\n",
    "# 'M0.1' :  5.09      5.16\n",
    "# 'M0.2' :  2.67      2.84\n",
    "\n",
    "# 'M3.1' :  0.91      0.86     1980         35.62%\n",
    "# 'M3.2' :  0.91      0.94\n",
    "# 'M3.3' :  0.85      0.91\n",
    "# 'M3.4' :  0.89      0.94\n",
    "# 'M3.5' :  0.94      0.86\n",
    "# 'M3.6' :  0.87      0.88\n",
    "\n",
    "# 'M4.1' :  4.90      4.99\n",
    "# 'M4.2' :  4.90      5.29\n",
    "\n",
    "# 'M5.1' :  0.84      1.26      \n",
    "# 'M5.2' :  0.95      1.11\n",
    "# 'M5.3' :  5.05      4.93\n",
    "\n",
    "# 'M7.1' :  0.73      0.92      757          13.62%\n",
    "# 'M7.2' :  0.94      1.08      2150         37.78%\n",
    "\n",
    "\n",
    "# Neural network models\n",
    "# NN M3  :  1.12      0.99\n",
    "# NN M4  :  0.82      1.21      1933         34%\n",
    "# NN M5  :  1.90      1.70\n",
    "# NN M6  :  3.58      4.30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Deep Learning Model 6"
   ]
  },
  {
   "attachments": {
    "Screenshot%20-%2014-11-2020%20,%2012_04_33.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot%20-%2014-11-2020%20,%2012_04_33.png](attachment:Screenshot%20-%2014-11-2020%20,%2012_04_33.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget --header=\"Host: storage.googleapis.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.193 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\" --header=\"Accept-Language: en-IN,en-GB;q=0.9,en-US;q=0.8,en;q=0.7\" --header=\"Referer: https://www.kaggle.com/\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/18599/1236839/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1605279325&Signature=T9NRy9SA1Wyg4nZaFs%2BmrVLXqoeGp2N3uwqbAhFYLPXt3a9O4aNHPHoYB13RkngLnX6QbWy3UDhe6obwcfIKu8HKn7RbuFK%2BRb7gY%2FWXBqAbzXvsxBLIoeI6hJv0trPXwCLo6m4766JIbxGdV3h1fatmEvaLoNezTTq2wvBazBUeMXRUw%2B%2BU1RrcAnwRkUkJuv2rdAX7nwERwnh%2BxFRvLcU%2F%2FYzCXIIdRRJqISOuUHCKenwEhLGZ47XLF%2FLdS8B39qjDkYqp52Fgjuae%2FieJKy8sXWNNAneP%2FRAbVsD3smQqkKkv05Bp3fmkYMQEWmEc5T4eVVXg%2BqAb5ysmX%2FQe7Q%3D%3D&response-content-disposition=attachment%3B+filename%3Dm5-forecasting-accuracy.zip\" -c -O 'm5-forecasting-accuracy.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip m5-forecasting-accuracy.zip\n",
    "\n",
    "# !apt-get update\n",
    "# !apt-get install wget\n",
    "\n",
    "# ! pip install pandas\n",
    "# ! pip install calender\n",
    "# ! pip install numpy\n",
    "# ! pip install datetime\n",
    "# ! pip install matplotlib\n",
    "# ! pip install collections\n",
    "# ! pip install random\n",
    "# ! pip install tqdm\n",
    "# ! pip install sklearn\n",
    "# ! pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "import pandas as pd\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import clear_output as cclear\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from math import sqrt\n",
    "import joblib\n",
    "# import xgboost as xgb\n",
    "from tensorflow.keras import backend as K \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(X):\n",
    "    return pd.read_csv(X)\n",
    "\n",
    "calender, sales_train_ev, sales_train_val, sell_prices, samp_sub = get_csv('calendar.csv'), \\\n",
    "                          get_csv('sales_train_evaluation.csv'), \\\n",
    "                          get_csv('sales_train_validation.csv'), get_csv('sell_prices.csv'), \\\n",
    "                          get_csv('sample_submission.csv')\n",
    "\n",
    "non_numeric_col_list = ['id','item_id','dept_id','cat_id','store_id','state_id','d', 'date']\n",
    "store_dict = {'CA_1':0, 'CA_2':0, 'CA_3':0, 'CA_4':0, 'WI_1':0, 'WI_2':0, 'WI_3':0, 'TX_1':0, 'TX_2':0, 'TX_3':0}\n",
    "\n",
    "# This function does feature engineering on sales_train_ev or sales_train_val\n",
    "# There is another feature engineering function for adding columns to dataframe containing rows of only onw store\n",
    "def feature_engineer(df):\n",
    "    day_columns = list(df.columns[6:])\n",
    "    other_var = list(df.columns[:6])\n",
    "    \n",
    "    df = pd.melt(df, id_vars = other_var, value_vars = day_columns)\n",
    "    df = df.rename(columns = {\"variable\": \"d\", \"value\": \"unit_sale\"})\n",
    "    # print(df.shape)\n",
    "\n",
    "    cal_dict = dict(zip(calender.d,calender.date))\n",
    "    df[\"date\"] = df[\"d\"].map(cal_dict)\n",
    "    # df.head()\n",
    "    \n",
    "    day_of_week_dict = dict(zip(calender.d,calender.wday))\n",
    "    df['day_of_week'] = df[\"d\"].map(day_of_week_dict)\n",
    "\n",
    "    month_no_dict = dict(zip(calender.d,calender.month))\n",
    "    df['month_no'] = df[\"d\"].map(month_no_dict)\n",
    "\n",
    "    l = [i[-2:] for i in list(calender.date)]\n",
    "    calender['day_of_month'] = l\n",
    "\n",
    "    day_of_month_dict = dict(zip(calender.d,calender.day_of_month))\n",
    "    df['day_of_month'] = df[\"d\"].map(day_of_month_dict)\n",
    "    return df\n",
    "\n",
    "def add_moving_avg_col(new_df,N, col_name):\n",
    "    l = np.convolve(list(new_df[col_name]), np.ones((N,))/N, mode='valid')\n",
    "    nl = [0]*(N-1)\n",
    "    nl.extend(list(l))\n",
    "    new_df[str(N)+'_d_mavg_'+str(col_name)] = nl\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def event1_check(index):\n",
    "    # Input is 0 to 1968, it is the index of Calender.CSV\n",
    "    # Output is True if there is event 1, False if no event 1\n",
    "    return not(calender.event_name_1[index] != calender.event_name_1[index])\n",
    "\n",
    "def event2_check(index):\n",
    "    # Input is 0 to 1968, it is the index of Calender.CSV\n",
    "    # Output is True if there is event 2, False if no event 2\n",
    "    return not(calender.event_name_2[index] != calender.event_name_2[index])\n",
    "\n",
    "days_with_event = []\n",
    "for i in range(len(calender)):\n",
    "    days_with_event.append(event1_check(i)) or (event2_check(i))\n",
    "    \n",
    "l = [int(i) for i in days_with_event]\n",
    "event_dict = dict(zip(calender.d, l))\n",
    "\n",
    "week_no_d_dict = dict(zip(calender.wm_yr_wk, calender.d))\n",
    "sell_prices['d'] = sell_prices['wm_yr_wk'].map(week_no_d_dict)\n",
    "sell_prices['item_d_col'] = sell_prices['item_id'] + sell_prices['d']\n",
    "sale_price_dict = dict(zip(sell_prices['item_d_col'], sell_prices['sell_price']))\n",
    "\n",
    "sell_prices = sell_prices.drop('d', 1)\n",
    "sell_prices = sell_prices.drop('item_d_col', 1)\n",
    "\n",
    "\n",
    "def one_feature_engineering_fun(df):\n",
    "    snap_dict = dict(zip(calender.d, calender['snap_'+df.state_id.iloc[0]]))   # Add snap or not column\n",
    "    df['snap_or_not'] = df[\"d\"].map(snap_dict)\n",
    "    print('snap added')\n",
    "    \n",
    "    df['event_or_not'] = df[\"d\"].map(event_dict)    # Adding event or not column\n",
    "    print('events added')\n",
    "    \n",
    "    df['item_d_col'] = df['item_id'] + df['d']      # Adding sale_price column\n",
    "    df['sale_price'] = df['item_d_col'].map(sale_price_dict)\n",
    "    df['sale_price'] = df['sale_price'].fillna(0)\n",
    "    print('sale prices added')\n",
    "    \n",
    "    df = df.drop('item_d_col', 1)                   # Undoing the columns we had to add\n",
    "    \n",
    "    df['Total_sale'] = df.unit_sale * df.sale_price  # Adding total sale column\n",
    "    \n",
    "    df = add_moving_avg_col(df,7, 'sale_price')     # Adding moving averages for sale price\n",
    "    df = add_moving_avg_col(df,14, 'sale_price')\n",
    "    df = add_moving_avg_col(df,30, 'sale_price')\n",
    "    df = add_moving_avg_col(df,60, 'sale_price')\n",
    "    df = add_moving_avg_col(df,180, 'sale_price')\n",
    "                 \n",
    "    df['day_of_month'] = df['day_of_month'].fillna(0)\n",
    "    df = df.astype({'day_of_month': 'int32'})      # Making day_of_month column as int\n",
    "    \n",
    "    df['date'] = df['date'].astype(str)\n",
    "    \n",
    "    df = add_moving_avg_col(df,7, 'unit_sale')     # Adding moving average columns\n",
    "    df = add_moving_avg_col(df,14, 'unit_sale')\n",
    "    df = add_moving_avg_col(df,30, 'unit_sale')\n",
    "    df = add_moving_avg_col(df,60, 'unit_sale')\n",
    "    df = add_moving_avg_col(df,180, 'unit_sale')\n",
    "    print('Total sale and Unit sale moving averages added')\n",
    "    \n",
    "    l1 = df.day_of_week == 1                       # we are adding an weekend or not column\n",
    "    l2 = df.day_of_week == 2\n",
    "\n",
    "    l1 = np.logical_or(l1,l2)\n",
    "    l1 = [elem*1 for elem in l1]\n",
    "    df['weekend'] = l1\n",
    "    print('Weekends added')\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def encode_cat_cols(new_df):\n",
    "    le = [0]*len(non_numeric_col_list)             # Encoding Categorical Columns\n",
    "    for i in range(len(non_numeric_col_list)):\n",
    "        print(\"Encoding col: \", non_numeric_col_list[i])\n",
    "        le[i] = LabelEncoder()\n",
    "        new_df[non_numeric_col_list[i]] = le[i].fit_transform( new_df[non_numeric_col_list[i]] )\n",
    "    return le, new_df\n",
    "\n",
    "# This function takes sales_train_ev or sales_train_val after feature_engineer() function has been called on them\n",
    "# and returns X, y and labelencoder after adding few more columns and encoding categorical features.\n",
    "def get_X_and_y(df, store_name):               \n",
    "    print('Store Name:', store_name)\n",
    "    new_df = df[df.store_id == store_name]        # Selecting rows for the selected store\n",
    "    \n",
    "    print('Store rows picked now working on adding columns...')\n",
    "    new_df = one_feature_engineering_fun(new_df)     # working on adding more columns and changing datatype of columns\n",
    "    \n",
    "    y = new_df.unit_sale                          # getting the label\n",
    "    new_df = new_df.drop('unit_sale', axis=1)\n",
    "    \n",
    "    print('Encoding categorical features...')\n",
    "    le, new_df = encode_cat_cols(new_df)          # Encoding Categorical Columns\n",
    "\n",
    "    X = new_df\n",
    "    \n",
    "    return X, y, le\n",
    "\n",
    "def reverse_long_form(le, X_test, train_out):\n",
    "    for i in range(len(non_numeric_col_list)):\n",
    "        X_test[non_numeric_col_list[i]] = le[i].inverse_transform(X_test[non_numeric_col_list[i]])\n",
    "\n",
    "    X_test['unit_sale'] = train_out\n",
    "    kk = X_test.pivot(index='id', columns='d')['unit_sale']\n",
    "    kk['id'] = kk.index\n",
    "    kk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    cols = list(kk)\n",
    "    cols = [cols[-1]] + cols[:-1]\n",
    "    kk = kk[cols]\n",
    "    \n",
    "    return kk\n",
    "\n",
    "\n",
    "def get_train_test(new_df, dept):\n",
    "    evaluation, validation = new_df.id.iloc[0].find('evaluation'), new_df.id.iloc[0].find('validation')\n",
    "    print('Picking rows for dept ', dept, '...')\n",
    "    new_df = new_df[new_df.dept_id == dept]\n",
    "\n",
    "    print('Total rows: ', len(new_df))\n",
    "    rows_per_day = len(new_df[new_df.d == 'd_1'])\n",
    "    print('Rows per day: ', rows_per_day)\n",
    "\n",
    "    new_df = one_feature_engineering_fun(new_df)\n",
    "\n",
    "    y = new_df.unit_sale                          # getting the label\n",
    "    new_df = new_df.drop('unit_sale', axis=1)\n",
    "\n",
    "    print('Encoding categorical features...')\n",
    "    le, new_df = encode_cat_cols(new_df)          # Encoding Categorical Columns\n",
    "\n",
    "    X = new_df\n",
    "\n",
    "    ev_train_start, ev_train_end, val_train_start, val_train_end = rows_per_day*(0), rows_per_day*1941,\\\n",
    "                                                                       rows_per_day*(0), rows_per_day*1913\n",
    "\n",
    "    if evaluation != -1:  # if evaluation data\n",
    "        print('Getting X_train, y_train...')\n",
    "        # fitiing only on one year data\n",
    "        X_train, y_train = X.iloc[ev_train_start:ev_train_end], y[ev_train_start:ev_train_end] \n",
    "        X_test, y_test = X.iloc[ev_train_end:], y[ev_train_end:] \n",
    "\n",
    "    if validation != -1:  # if validation data\n",
    "        print('Getting X_train, y_train...')\n",
    "        X_train, y_train = X.iloc[val_train_start:val_train_end], y[val_train_start:val_train_end]\n",
    "        X_test, y_test = X.iloc[val_train_end:], y[val_train_end:]\n",
    "\n",
    "    cclear()\n",
    "    print('X_train len', len(X_train), 'y_train len', len(y_train), 'X_test len', len(X_test))\n",
    "    print('Done.')\n",
    "    return le, X_train, y_train, X_test\n",
    "\n",
    "class terminate_on_acc(tf.keras.callbacks.Callback):    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        loss = logs['loss']\n",
    "        if loss < target_loss:\n",
    "            self.model.stop_training = True\n",
    "terminate_on_acc = terminate_on_acc()\n",
    "\n",
    "def train_NN(X_train, y_train, X_test, epoch_no, model_name, model):\n",
    "    \n",
    "    print('Shaping data for Neural Network...')\n",
    "    X_train, y_train, X_test = np.matrix(X_train).astype(np.float32), np.matrix(y_train).astype(np.float32),\\\n",
    "                               np.matrix(X_test).astype(np.float32)\n",
    "    X_train, y_train = tf.convert_to_tensor(X_train), tf.convert_to_tensor(y_train)\n",
    "    X_test = tf.convert_to_tensor(X_test)\n",
    "    y_train = tf.reshape(y_train, shape = (np.shape(X_train)[0], 1))\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(filepath='model_'+str(model_name)+'.h5', monitor='loss', verbose=1, \n",
    "                                 save_best_only=True, mode='auto')\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=epoch_no, verbose=1, callbacks = [terminate_on_acc, checkpoint])\n",
    "    print('Just making the predictions...')\n",
    "    y_hat = model.predict(X_test)\n",
    "    print('Done.')\n",
    "    \n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def predict_dept(df, dept_name, model, epoch_no):\n",
    "    evaluation, validation = df.id.iloc[0].find('evaluation'), df.id.iloc[0].find('validation')\n",
    "    \n",
    "    le, X_train, y_train, X_test = get_train_test(df, dept_name)\n",
    "    \n",
    "    if evaluation != -1:  # if evaluation data\n",
    "        y_hat = train_NN(X_train, y_train, X_test, epoch_no, str(dept_name)+'_M6_ev', model)\n",
    "    if validation != -1:  # if validation data\n",
    "        y_hat = train_NN(X_train, y_train, X_test, epoch_no, str(dept_name)+'_M6_val', model)\n",
    "    \n",
    "    print('Reversing the long form...')\n",
    "    out_df = reverse_long_form(le, X_test, y_hat)\n",
    "    out_df = pd.DataFrame(out_df)\n",
    "\n",
    "    l = []      # In this part we rename the columns to F_1, F_2 ....\n",
    "    for i in range(1,29):\n",
    "        l.append('F'+str(i))\n",
    "    l = ['id']+l\n",
    "    \n",
    "    print('Writing the output to CSV...')\n",
    "    out_df.columns = l\n",
    "    if evaluation != -1:  # if evaluation data\n",
    "        out_df.to_csv(str(dept_name)+'_M6_ev.csv', index=False)\n",
    "    if validation != -1:  # if validation data\n",
    "        out_df.to_csv(str(dept_name)+'_M6_val.csv', index=False)\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for Evaluation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing Evaluation CSV...\n",
      "CPU times: user 34.6 s, sys: 9.07 s, total: 43.6 s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Preparing Evaluation CSV...')\n",
    "df = sales_train_ev.copy()\n",
    "empty_list = [0]*30490\n",
    "for i in range(1942, 1970):\n",
    "    df['d_'+str(i)] = empty_list\n",
    "df = feature_engineer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FOODS_1',\n",
       " 'FOODS_2',\n",
       " 'FOODS_3',\n",
       " 'HOBBIES_1',\n",
       " 'HOBBIES_2',\n",
       " 'HOUSEHOLD_1',\n",
       " 'HOUSEHOLD_2'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.dept_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can fit the same model to all stores sequentially without recompliling everytime, that can be an experiemnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 442 ms, sys: 239 ms, total: 681 ms\n",
      "Wall time: 694 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_loss = 0.7\n",
    "\n",
    "model = Sequential()        \n",
    "model.add(Dense(75, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(250))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 8074560 y_train len 8074560 X_test len 116480\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 8074560 samples\n",
      "Epoch 1/4\n",
      "8073952/8074560 [============================>.] - ETA: 0s - loss: 26.9072\n",
      "Epoch 00001: loss improved from inf to 26.90553, saving model to model_HOBBIES_1_M6_ev.h5\n",
      "8074560/8074560 [==============================] - 505s 62us/sample - loss: 26.9055\n",
      "Epoch 2/4\n",
      "8073952/8074560 [============================>.] - ETA: 0s - loss: 5.3610\n",
      "Epoch 00002: loss improved from 26.90553 to 5.36108, saving model to model_HOBBIES_1_M6_ev.h5\n",
      "8074560/8074560 [==============================] - 502s 62us/sample - loss: 5.3611\n",
      "Epoch 3/4\n",
      "8073888/8074560 [============================>.] - ETA: 0s - loss: 5.3612\n",
      "Epoch 00003: loss improved from 5.36108 to 5.36106, saving model to model_HOBBIES_1_M6_ev.h5\n",
      "8074560/8074560 [==============================] - 502s 62us/sample - loss: 5.3611\n",
      "Epoch 4/4\n",
      "8074368/8074560 [============================>.] - ETA: 0s - loss: 5.3613\n",
      "Epoch 00004: loss did not improve from 5.36106\n",
      "8074560/8074560 [==============================] - 502s 62us/sample - loss: 5.3612\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 43min 33s, sys: 4min 12s, total: 47min 45s\n",
      "Wall time: 34min 56s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# predict_dept(df, 'HOBBIES_1', model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 2892090 y_train len 2892090 X_test len 41720\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 2892090 samples\n",
      "Epoch 1/4\n",
      "2891552/2892090 [============================>.] - ETA: 0s - loss: 0.5697\n",
      "Epoch 00001: loss improved from inf to 0.56964, saving model to model_HOBBIES_2_M6_ev.h5\n",
      "2892090/2892090 [==============================] - 215s 74us/sample - loss: 0.5696\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 5min 36s, sys: 37.1 s, total: 6min 13s\n",
      "Wall time: 4min 1s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# predict_dept(df, 'HOBBIES_2', model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 10326120 y_train len 10326120 X_test len 148960\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 10326120 samples\n",
      "Epoch 1/4\n",
      "10325984/10326120 [============================>.] - ETA: 0s - loss: 6.8591\n",
      "Epoch 00001: loss improved from inf to 6.85908, saving model to model_HOUSEHOLD_1_M6_ev.h5\n",
      "10326120/10326120 [==============================] - 766s 74us/sample - loss: 6.8591\n",
      "Epoch 2/4\n",
      "10325856/10326120 [============================>.] - ETA: 0s - loss: 6.2420\n",
      "Epoch 00002: loss improved from 6.85908 to 6.24192, saving model to model_HOUSEHOLD_1_M6_ev.h5\n",
      "10326120/10326120 [==============================] - 767s 74us/sample - loss: 6.2419\n",
      "Epoch 3/4\n",
      "10325984/10326120 [============================>.] - ETA: 0s - loss: 6.1615\n",
      "Epoch 00003: loss improved from 6.24192 to 6.16147, saving model to model_HOUSEHOLD_1_M6_ev.h5\n",
      "10326120/10326120 [==============================] - 766s 74us/sample - loss: 6.1615\n",
      "Epoch 4/4\n",
      "10326048/10326120 [============================>.] - ETA: 0s - loss: 6.1286\n",
      "Epoch 00004: loss improved from 6.16147 to 6.12867, saving model to model_HOUSEHOLD_1_M6_ev.h5\n",
      "10326120/10326120 [==============================] - 763s 74us/sample - loss: 6.1287\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 1h 15min 29s, sys: 8min 21s, total: 1h 23min 50s\n",
      "Wall time: 52min 32s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# predict_dept(df, 'HOUSEHOLD_1', model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 9996150 y_train len 9996150 X_test len 144200\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 9996150 samples\n",
      "Epoch 1/4\n",
      "9995968/9996150 [============================>.] - ETA: 0s - loss: 0.5549\n",
      "Epoch 00001: loss improved from inf to 0.55485, saving model to model_HOUSEHOLD_2_M6_ev.h5\n",
      "9996150/9996150 [==============================] - 743s 74us/sample - loss: 0.5549\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 19min 11s, sys: 2min 15s, total: 21min 27s\n",
      "Wall time: 13min 50s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# predict_dept(df, 'HOUSEHOLD_2', model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 4192560 y_train len 4192560 X_test len 60480\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 4192560 samples\n",
      "Epoch 1/3\n",
      "4192224/4192560 [============================>.] - ETA: 0s - loss: 18.7905\n",
      "Epoch 00001: loss improved from inf to 18.78930, saving model to model_FOODS_1_M6_ev.h5\n",
      "4192560/4192560 [==============================] - 557s 133us/sample - loss: 18.7893\n",
      "Epoch 2/3\n",
      "4192544/4192560 [============================>.] - ETA: 0s - loss: 7.0608\n",
      "Epoch 00002: loss improved from 18.78930 to 7.06076, saving model to model_FOODS_1_M6_ev.h5\n",
      "4192560/4192560 [==============================] - 558s 133us/sample - loss: 7.0608\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 25min 52s, sys: 3min 4s, total: 28min 57s\n",
      "Wall time: 19min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_loss = 9\n",
    "\n",
    "model = Sequential()        \n",
    "model.add(Dense(75, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "predict_dept(df, 'FOODS_1', model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 7725180 y_train len 7725180 X_test len 111440\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 7725180 samples\n",
      "Epoch 1/4\n",
      "7724864/7725180 [============================>.] - ETA: 0s - loss: 26.7001\n",
      "Epoch 00001: loss improved from inf to 26.69927, saving model to model_FOODS_2_M6_ev.h5\n",
      "7725180/7725180 [==============================] - 999s 129us/sample - loss: 26.6993\n",
      "Epoch 2/4\n",
      "7724768/7725180 [============================>.] - ETA: 0s - loss: 5.6448\n",
      "Epoch 00002: loss improved from 26.69927 to 5.64486, saving model to model_FOODS_2_M6_ev.h5\n",
      "7725180/7725180 [==============================] - 999s 129us/sample - loss: 5.6449\n",
      "Epoch 3/4\n",
      "7724896/7725180 [============================>.] - ETA: 0s - loss: 5.5973\n",
      "Epoch 00003: loss improved from 5.64486 to 5.59722, saving model to model_FOODS_2_M6_ev.h5\n",
      "7725180/7725180 [==============================] - 998s 129us/sample - loss: 5.5972\n",
      "Epoch 4/4\n",
      "7725120/7725180 [============================>.] - ETA: 0s - loss: 5.5742\n",
      "Epoch 00004: loss improved from 5.59722 to 5.57416, saving model to model_FOODS_2_M6_ev.h5\n",
      "7725180/7725180 [==============================] - 997s 129us/sample - loss: 5.5742\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 1h 31min 28s, sys: 10min 45s, total: 1h 42min 14s\n",
      "Wall time: 1h 8min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_loss = 0.7\n",
    "\n",
    "model = Sequential()        \n",
    "model.add(Dense(75, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(20))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "predict_dept(df, 'FOODS_2', model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# predict_dept(df, 'FOODS_3', model, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training for Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.5 s, sys: 9.02 s, total: 38.5 s\n",
      "Wall time: 38.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = sales_train_val.copy()\n",
    "empty_list = [0]*30490\n",
    "for i in range(1914, 1942):\n",
    "    df['d_'+str(i)] = empty_list\n",
    "df = feature_engineer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FOODS_1',\n",
       " 'FOODS_2',\n",
       " 'FOODS_3',\n",
       " 'HOBBIES_1',\n",
       " 'HOBBIES_2',\n",
       " 'HOUSEHOLD_1',\n",
       " 'HOUSEHOLD_2'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.dept_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 75.5 ms, sys: 0 ns, total: 75.5 ms\n",
      "Wall time: 72.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_loss = 0.7\n",
    "\n",
    "model = Sequential()        \n",
    "model.add(Dense(75, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(250))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 7958080 y_train len 7958080 X_test len 116480\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 7958080 samples\n",
      "Epoch 1/4\n",
      "7957440/7958080 [============================>.] - ETA: 0s - loss: 32.5441\n",
      "Epoch 00001: loss improved from inf to 32.54179, saving model to model_HOBBIES_1_M6_val.h5\n",
      "7958080/7958080 [==============================] - 496s 62us/sample - loss: 32.5418\n",
      "Epoch 2/4\n",
      "7957312/7958080 [============================>.] - ETA: 0s - loss: 5.3768\n",
      "Epoch 00002: loss improved from 32.54179 to 5.37663, saving model to model_HOBBIES_1_M6_val.h5\n",
      "7958080/7958080 [==============================] - 497s 62us/sample - loss: 5.3766\n",
      "Epoch 3/4\n",
      "7958016/7958080 [============================>.] - ETA: 0s - loss: 5.3609\n",
      "Epoch 00003: loss improved from 5.37663 to 5.36083, saving model to model_HOBBIES_1_M6_val.h5\n",
      "7958080/7958080 [==============================] - 496s 62us/sample - loss: 5.3608\n",
      "Epoch 4/4\n",
      "7957600/7958080 [============================>.] - ETA: 0s - loss: 5.5660\n",
      "Epoch 00004: loss did not improve from 5.36083\n",
      "7958080/7958080 [==============================] - 495s 62us/sample - loss: 5.5661\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 42min 57s, sys: 4min 9s, total: 47min 6s\n",
      "Wall time: 34min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "predict_dept(df, 'HOBBIES_1', model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 2850370 y_train len 2850370 X_test len 41720\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 2850370 samples\n",
      "Epoch 1/4\n",
      "2850304/2850370 [============================>.] - ETA: 0s - loss: 0.5657\n",
      "Epoch 00001: loss improved from inf to 0.56571, saving model to model_HOBBIES_2_M6_val.h5\n",
      "2850370/2850370 [==============================] - 213s 75us/sample - loss: 0.5657\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 5min 31s, sys: 36.3 s, total: 6min 8s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "predict_dept(df, 'HOBBIES_2', model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 10177160 y_train len 10177160 X_test len 148960\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 10177160 samples\n",
      "Epoch 1/4\n",
      "10176576/10177160 [============================>.] - ETA: 0s - loss: 7.5644\n",
      "Epoch 00001: loss improved from inf to 7.56468, saving model to model_HOUSEHOLD_1_M6_val.h5\n",
      "10177160/10177160 [==============================] - 758s 74us/sample - loss: 7.5647\n",
      "Epoch 2/4\n",
      "10176704/10177160 [============================>.] - ETA: 0s - loss: 7.5636\n",
      "Epoch 00002: loss improved from 7.56468 to 7.56354, saving model to model_HOUSEHOLD_1_M6_val.h5\n",
      "10177160/10177160 [==============================] - 757s 74us/sample - loss: 7.5635\n",
      "Epoch 3/4\n",
      "10176672/10177160 [============================>.] - ETA: 0s - loss: 7.5637\n",
      "Epoch 00003: loss did not improve from 7.56354\n",
      "10177160/10177160 [==============================] - 759s 75us/sample - loss: 7.5636\n",
      "Epoch 4/4\n",
      "10176896/10177160 [============================>.] - ETA: 0s - loss: 7.5634\n",
      "Epoch 00004: loss did not improve from 7.56354\n",
      "10177160/10177160 [==============================] - 758s 74us/sample - loss: 7.5636\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 1h 14min 32s, sys: 8min 11s, total: 1h 22min 44s\n",
      "Wall time: 52min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_loss = 0.7\n",
    "\n",
    "model = Sequential()        \n",
    "model.add(Dense(75, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "predict_dept(df, 'HOUSEHOLD_1', model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 9851950 y_train len 9851950 X_test len 144200\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 9851950 samples\n",
      "Epoch 1/4\n",
      "9851520/9851950 [============================>.] - ETA: 0s - loss: 0.6896\n",
      "Epoch 00001: loss improved from inf to 0.68960, saving model to model_HOUSEHOLD_2_M6_val.h5\n",
      "9851950/9851950 [==============================] - 730s 74us/sample - loss: 0.6896\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 18min 50s, sys: 2min 13s, total: 21min 4s\n",
      "Wall time: 13min 35s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# predict_dept(df, 'HOUSEHOLD_2', model, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 4132080 y_train len 4132080 X_test len 60480\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 4132080 samples\n",
      "Epoch 1/4\n",
      "4131616/4132080 [============================>.] - ETA: 0s - loss: 9.3012\n",
      "Epoch 00001: loss improved from inf to 9.30115, saving model to model_FOODS_1_M6_val.h5\n",
      "4132080/4132080 [==============================] - 308s 75us/sample - loss: 9.3012\n",
      "Epoch 2/4\n",
      "4131776/4132080 [============================>.] - ETA: 0s - loss: 9.2947\n",
      "Epoch 00002: loss improved from 9.30115 to 9.29460, saving model to model_FOODS_1_M6_val.h5\n",
      "4132080/4132080 [==============================] - 307s 74us/sample - loss: 9.2946\n",
      "Epoch 3/4\n",
      "4131456/4132080 [============================>.] - ETA: 0s - loss: 9.2949\n",
      "Epoch 00003: loss improved from 9.29460 to 9.29451, saving model to model_FOODS_1_M6_val.h5\n",
      "4132080/4132080 [==============================] - 307s 74us/sample - loss: 9.2945\n",
      "Epoch 4/4\n",
      "4131808/4132080 [============================>.] - ETA: 0s - loss: 9.2945\n",
      "Epoch 00004: loss did not improve from 9.29451\n",
      "4132080/4132080 [==============================] - 306s 74us/sample - loss: 9.2946\n",
      "Just making the predictions...\n",
      "Done.\n",
      "Reversing the long form...\n",
      "Writing the output to CSV...\n",
      "Done.\n",
      "CPU times: user 30min 13s, sys: 3min 16s, total: 33min 29s\n",
      "Wall time: 21min 4s\n"
     ]
    }
   ],
   "source": [
    "%%%%time\n",
    "target_loss = 0.7\n",
    "\n",
    "model = Sequential()        \n",
    "model.add(Dense(75, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "predict_dept(df, 'FOODS_1', model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train len 7613740 y_train len 7613740 X_test len 111440\n",
      "Done.\n",
      "Shaping data for Neural Network...\n",
      "Train on 7613740 samples\n",
      "Epoch 1/4\n",
      "7613312/7613740 [============================>.] - ETA: 0s - loss: 7.2465\n",
      "Epoch 00001: loss improved from inf to 7.24645, saving model to model_FOODS_2_M6_val.h5\n",
      "7613740/7613740 [==============================] - 566s 74us/sample - loss: 7.2465\n",
      "Epoch 2/4\n",
      "7613664/7613740 [============================>.] - ETA: 0s - loss: 7.2472\n",
      "Epoch 00002: loss did not improve from 7.24645\n",
      "7613740/7613740 [==============================] - 567s 74us/sample - loss: 7.2472\n",
      "Epoch 3/4\n",
      "7613440/7613740 [============================>.] - ETA: 0s - loss: 7.2462\n",
      "Epoch 00003: loss improved from 7.24645 to 7.24640, saving model to model_FOODS_2_M6_val.h5\n",
      "7613740/7613740 [==============================] - 566s 74us/sample - loss: 7.2464\n",
      "Epoch 4/4\n",
      "7054048/7613740 [==========================>...] - ETA: 41s - loss: 7.2673"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target_loss = 0.7\n",
    "\n",
    "model = Sequential()        \n",
    "model.add(Dense(75, activation='relu', input_shape=(26,)))\n",
    "model.add(Dense(150))\n",
    "model.add(Dense(250))\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "predict_dept(df, 'FOODS_2', model, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "# predict_dept(df, 'FOODS_3', model, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging and Making Submissible CSV ###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/iamsh/Desktop/CS1 Kaggle Files/DL/M6/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun(name):\n",
    "    return pd.read_csv(path+name+'.csv')\n",
    "\n",
    "food1ev, food2ev, food3ev = fun('FOODS_1_M6_ev'), fun('FOODS_2_M6_ev'), fun('FOODS_3_M6_ev')\n",
    "hobbies1ev, hobbies2ev = fun('HOBBIES_1_M6_ev'), fun('HOBBIES_2_M6_ev')\n",
    "house1ev, house2ev = fun('HOUSEHOLD_1_M6_ev'), fun('HOUSEHOLD_2_M6_ev')\n",
    "\n",
    "food1val, food2val, food3val = fun('FOODS_1_M6_val'), fun('FOODS_2_M6_val'), fun('FOODS_3_M6_val')\n",
    "hobbies1val, hobbies2val = fun('HOBBIES_1_M6_val'), fun('HOBBIES_2_M6_val')\n",
    "house1val, house2val = fun('HOUSEHOLD_1_M6_val'), fun('HOUSEHOLD_2_M6_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_out_df_ev = pd.concat([food1ev, food2ev, food3ev, hobbies1ev, hobbies2ev, house1ev, house2ev], \n",
    "                           ignore_index=False)\n",
    "main_out_df_val = pd.concat([food1val, food2val, food3val, hobbies1val, hobbies2val, house1val, house2val],\n",
    "                            ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(df, main_out):\n",
    "    df['sp_index'] = (df.index)\n",
    "    index_dict = dict(zip(df.id, df.sp_index))\n",
    "    df = df.drop('sp_index', axis=1)\n",
    "    main_out['sp_index'] = main_out[\"id\"].map(index_dict)\n",
    "    main_out = main_out.sort_values(by='sp_index', axis=0)\n",
    "    main_out = main_out.drop('sp_index', axis=1)\n",
    "    return main_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1 = reorder(pd.read_csv('C:/Users/iamsh/Desktop/CS1 Kaggle Files/Given Files/sales_train_evaluation.csv'), main_out_df_ev)\n",
    "out_2 = reorder(pd.read_csv('C:/Users/iamsh/Desktop/CS1 Kaggle Files/Given Files/sales_train_validation.csv'), main_out_df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([out_1, out_2], ignore_index=False)\n",
    "df = df.round(2)\n",
    "df.to_csv('submissible_nn_M6.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1_evaluation</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1_evaluation</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1_evaluation</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1_evaluation</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1_evaluation</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>...</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60975</th>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-1.43</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60976</th>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1.21</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-1.23</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60977</th>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-1.84</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60978</th>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.71</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60979</th>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60980 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id    F1    F2    F3    F4    F5    F6  \\\n",
       "0      HOBBIES_1_001_CA_1_evaluation  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "1      HOBBIES_1_002_CA_1_evaluation  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "2      HOBBIES_1_003_CA_1_evaluation  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "3      HOBBIES_1_004_CA_1_evaluation  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "4      HOBBIES_1_005_CA_1_evaluation  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "...                              ...   ...   ...   ...   ...   ...   ...   \n",
       "60975    FOODS_3_823_WI_3_validation  0.08  0.07  0.06  0.05 -1.40  0.19   \n",
       "60976    FOODS_3_824_WI_3_validation  0.08  0.07  0.06  0.05 -1.21  0.19   \n",
       "60977    FOODS_3_825_WI_3_validation  0.08  0.07  0.06  0.05 -1.81  0.19   \n",
       "60978    FOODS_3_826_WI_3_validation  0.09  0.08  0.07  0.06 -0.71  0.19   \n",
       "60979    FOODS_3_827_WI_3_validation  0.09  0.08  0.07  0.06 -0.59  0.19   \n",
       "\n",
       "         F7    F8    F9  ...   F19   F20   F21   F22   F23   F24   F25   F26  \\\n",
       "0      0.71  0.71  0.71  ...  0.71  0.71  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "1      0.71  0.71  0.71  ...  0.71  0.71  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "2      0.71  0.71  0.71  ...  0.71  0.71  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "3      0.71  0.71  0.71  ...  0.71  0.71  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "4      0.71  0.71  0.71  ...  0.71  0.71  0.71  0.71  0.71  0.71  0.71  0.71   \n",
       "...     ...   ...   ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "60975  0.14  0.05  0.04  ... -1.43  0.10  0.09  0.06  0.05  0.04  0.03 -1.43   \n",
       "60976  0.14  0.05  0.04  ... -1.24  0.10  0.09  0.06  0.05  0.04  0.03 -1.23   \n",
       "60977  0.14  0.05  0.04  ... -1.84  0.10  0.09  0.06  0.05  0.04  0.03 -1.84   \n",
       "60978  0.15  0.05  0.04  ... -0.74  0.10  0.09  0.06  0.05  0.04  0.03 -0.73   \n",
       "60979  0.15  0.05  0.04  ... -0.62  0.10  0.09  0.06  0.05  0.04  0.03 -0.62   \n",
       "\n",
       "        F27   F28  \n",
       "0      0.71  0.71  \n",
       "1      0.71  0.71  \n",
       "2      0.71  0.71  \n",
       "3      0.71  0.71  \n",
       "4      0.71  0.71  \n",
       "...     ...   ...  \n",
       "60975  0.11  0.10  \n",
       "60976  0.11  0.10  \n",
       "60977  0.11  0.10  \n",
       "60978  0.11  0.10  \n",
       "60979  0.11  0.10  \n",
       "\n",
       "[60980 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('submissible_nn_M6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models I tried and their loss values by epoch\n",
    "# model = Sequential()        \n",
    "# model.add(Dense(5, activation='relu', input_shape=(26,)))\n",
    "# model.add(Dense(50))\n",
    "# model.add(Dense(10))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# epoch 1 loss 7 \n",
    "###################################################\n",
    "# target_loss = 0.7\n",
    "\n",
    "# model = Sequential()        \n",
    "# model.add(Dense(50, activation='relu', input_shape=(26,)))\n",
    "# model.add(Dense(250))\n",
    "# model.add(Dense(500))\n",
    "# model.add(Dense(250))\n",
    "# model.add(Dense(50))\n",
    "# model.add(Dense(10))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# y_hat = train_NN(X_train, y_train, X_test, 100, 'HOBBIES_1_ev', model)\n",
    "\n",
    "# # Epoch 5, loss 5.36\n",
    "####################################################\n",
    "# target_loss = 0.7\n",
    "\n",
    "# model = Sequential()        \n",
    "# model.add(Dense(10, activation='relu', input_shape=(26,)))\n",
    "# model.add(Dense(150))\n",
    "# model.add(Dense(150))\n",
    "# model.add(Dense(50))\n",
    "# model.add(Dense(10))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# y_hat = train_NN(X_train, y_train, X_test, 50, 'HOBBIES_1_ev', model)\n",
    "# Epoch 4, loss 4.5\n",
    "###########################################\n",
    "# target_loss = 0.7\n",
    "\n",
    "# model = Sequential()        \n",
    "# model.add(Dense(75, activation='relu', input_shape=(26,)))\n",
    "# model.add(Dense(150))\n",
    "# model.add(Dense(150))\n",
    "# model.add(Dense(75))\n",
    "# model.add(Dense(25))\n",
    "# model.add(Dense(1))\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# y_hat = train_NN(X_train, y_train, X_test, 50, 'HOBBIES_1_ev', model)\n",
    "# e 5, l 4.3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
