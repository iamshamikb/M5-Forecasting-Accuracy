{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "aI0Ucqk1TIui"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "These installations will be required to run the code.\n",
    "'''\n",
    "# !unzip m5-forecasting-accuracy.zip\n",
    "\n",
    "# !apt-get update\n",
    "# !apt-get install wget\n",
    "\n",
    "# ! pip install pandas\n",
    "# ! pip install calender\n",
    "# ! pip install numpy\n",
    "# ! pip install datetime\n",
    "# ! pip install matplotlib\n",
    "# ! pip install collections\n",
    "# ! pip install random\n",
    "# ! pip install tqdm\n",
    "# ! pip install sklearn\n",
    "# ! pip install lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output \n",
    "import pandas as pd\n",
    "import calendar\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from IPython.display import clear_output as cclear\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "import lightgbm as lgb\n",
    "from math import sqrt\n",
    "from itertools import zip_longest\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_randFloat\n",
    "import joblib\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Import myfeature.py\n",
    "'''\n",
    "import myfeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fetching the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get the m5-forecasting-accuracy.zip from data section here at Kaggle. A Kaggle account is required-\n",
    "https://www.kaggle.com/c/m5-forecasting-accuracy/data.\n",
    "\n",
    "It is suggested to use cliget extension on Firefox Browser to get the files. \n",
    "1. Just add the extension and click on 'Download All' button on Kaggle page's Data section.\n",
    "2. Now as the download begins you may pause it immediately as downloading is not required.\n",
    "3. Now click on the extension icon and select 'm5-forecasting-accuracy.zip' and you will be shown a link.\n",
    "4. Paste that link here in any cell with an exclamation mark prefixed to it and execute the cell to download the data.\n",
    "5. Unzip using '!unzip m5-forecasting-accuracy.zip' command.\n",
    "6. Done.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Loading CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "id": "CD1ZprJU8lLL"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We need all CSVs except sample_submission.csv to perform the feature engineering.\n",
    "'''\n",
    "\n",
    "def get_csv(X):\n",
    "    return pd.read_csv(X)\n",
    "\n",
    "calender, sales_train_ev, sales_train_val, sell_prices =  get_csv('calendar.csv'), \\\n",
    "                                                          get_csv('sales_train_evaluation.csv'), \\\n",
    "                                                          get_csv('sales_train_validation.csv'), \\\n",
    "                                                          get_csv('sell_prices.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Creating some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "non_numeric_col_list = ['id','item_id','dept_id','cat_id','store_id','state_id','d', 'date']\n",
    "store_dict = {'CA_1':0, 'CA_2':0, 'CA_3':0, 'CA_4':0, 'WI_1':0, 'WI_2':0, 'WI_3':0, 'TX_1':0, 'TX_2':0, 'TX_3':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We are creating a dict for days with at least one event.\n",
    "'''\n",
    "\n",
    "days_with_event = []\n",
    "for i in range(len(calender)):\n",
    "    days_with_event.append(myfeature.event1_check(i)) or (myfeature.event2_check(i))\n",
    "    \n",
    "l = [int(i) for i in days_with_event]\n",
    "event_dict = dict(zip(calender.d, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "week_no_d_dict = dict(zip(calender.wm_yr_wk, calender.d))\n",
    "sell_prices['d'] = sell_prices['wm_yr_wk'].map(week_no_d_dict)\n",
    "sell_prices['item_d_col'] = sell_prices['item_id'] + sell_prices['d']\n",
    "sale_price_dict = dict(zip(sell_prices['item_d_col'], sell_prices['sell_price']))\n",
    "\n",
    "sell_prices = sell_prices.drop('d', 1)\n",
    "sell_prices = sell_prices.drop('item_d_col', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Generic Hyperparameter Tuning Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "This is the generic tuning code used for tuning on all strategies tried.\n",
    "'''\n",
    "param_list_to_try = {\n",
    "            'subsample' : sp_randFloat(, ),\n",
    "            'learning_rate' : sp_randFloat(, ),\n",
    "            'num_leaves' : sp_randint(, ),\n",
    "            'min_data_in_leaf' : sp_randint(, ),\n",
    "            'reg_lambda' : sp_randFloat(, ),\n",
    "            'feature_fraction' :sp_randFloat(, ),\n",
    "            'max_bin' : sp_randint(, ),\n",
    "            'n_estimators' : sp_randint(, )}\n",
    "\n",
    "no_of_hyperparameters = \n",
    "clf = LGBMRegressor(boosting_type = 'gbdt', \n",
    "                    objective = 'tweedie', \n",
    "                    tweedie_variance_power = ,\n",
    "                    metric = 'rmse',\n",
    "                    subsample_freq = ,\n",
    "                    boost_from_average = False)\n",
    "\n",
    "random_search = RandomizedSearchCV( estimator = clf, \n",
    "                                    param_distributions = param_list_to_try,\n",
    "                                    n_iter = no_of_hyperparameters,\n",
    "                                    scoring = make_scorer(mse, greater_is_better = False), \n",
    "                                    cv = , \n",
    "                                    refit = True, \n",
    "                                    random_state = 314, \n",
    "                                    verbose = True)\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "print('Best score reached: {} with params: {} '.format(random_search.best_score_, random_search.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Hyperparameter Tuning Strategy - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "In this tuning strategy we do hyperparameter tuning for entire data and add all the features we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = myfeature.feature_engineer(sales_train_ev)\n",
    "\n",
    "print('Store Name:', 'CA_1')\n",
    "new_df = df[df.store_id == 'CA_1']        # Selecting rows for the selected store\n",
    "\n",
    "print('Store rows picked now working on adding columns...')\n",
    "new_df = myfeature.one_feature_engineering_fun(new_df)     # working on adding more columns and changing datatype of columns\n",
    "\n",
    "y = new_df.unit_sale                          # getting the label\n",
    "new_df = new_df.drop('unit_sale', axis=1)\n",
    "\n",
    "print('Encoding categorical features...')\n",
    "le, new_df = myfeature.encode_cat_cols(new_df)          # Encoding Categorical Columns\n",
    "\n",
    "X = new_df\n",
    "\n",
    "X_train, y_train = X.iloc[0:3049*1913], y[:3049*1913]\n",
    "X_test, y_test = X.iloc[3049*1913:], y[3049*1913:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Hyperparameter Tuning Strategy - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Here we add all the columns and do hyperparameter tuning on only one year of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = myfeature.feature_engineer(sales_train_ev)\n",
    "\n",
    "print('Store Name:', 'CA_1')\n",
    "new_df = df[df.store_id == 'CA_1']        # Selecting rows for the selected store\n",
    "\n",
    "print('Store rows picked now working on adding columns...')\n",
    "new_df = myfeature.one_feature_engineering_fun(new_df)     # working on adding more columns and changing datatype of columns\n",
    "\n",
    "y = new_df.unit_sale                          # getting the label\n",
    "new_df = new_df.drop('unit_sale', axis=1)\n",
    "\n",
    "print('Encoding categorical features...')\n",
    "le, new_df = myfeature.encode_cat_cols(new_df)          # Encoding Categorical Columns\n",
    "\n",
    "X = new_df\n",
    "\n",
    "X_train, y_train = X.iloc[3049*(1941-365):3049*1941], y[3049*(1941-365):3049*1941]\n",
    "X_test, y_test = X.iloc[3049*1941:], y[3049*1941:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Hyperparameter Tuning Strategy - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Here we do not add any column after initial feature_engineer() function. We use data of one year only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = myfeature.feature_engineer(sales_train_ev)\n",
    "\n",
    "X, y, le = myfeature.get_X_and_y_withou_adding_more_features(df, 'CA_1')\n",
    "\n",
    "X_train, y_train = X.iloc[3049*(1941-365):3049*1941], y[3049*(1941-365):3049*1941]\n",
    "X_test, y_test = X.iloc[3049*1941:], y[3049*1941:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Hyperparameter Tuning Strategy - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Tuning for one dept and all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "'''\n",
    "For evaluation csv, we add columns from 1942 to 1970 so that we can predict. We will need these columns to transform\n",
    "the data into long form.\n",
    "Then we use the feature_engineer function to add the features and make the transformation.\n",
    "'''\n",
    "\n",
    "df = sales_train_ev.copy()\n",
    "empty_list = [0]*30490\n",
    "for i in range(1942, 1970):\n",
    "    df['d_'+str(i)] = empty_list\n",
    "df = myfeature.feature_engineer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "'''\n",
    "The Generic code for Hyperparameter Tuning requires 'dept_name_to_tune_on' variable to have the dept name to be specified.\n",
    "Among departments FOODS_1 has less no of rows so tuning will take lesser time, however any dept can be used. \n",
    "'''\n",
    "\n",
    "new_df = df\n",
    "new_df = new_df[new_df.dept_id == dept_name_to_tune_on]\n",
    "print('Total rows: ', len(new_df))\n",
    "\n",
    "rows_per_day = len(new_df[new_df.d == 'd_1'])\n",
    "print('Rows per day: ', rows_per_day)\n",
    "\n",
    "new_df['day_of_month'] = new_df['day_of_month'].fillna(0)\n",
    "new_df = new_df.astype({'day_of_month': 'int32'})               # Making day_of_month column as int\n",
    "new_df['date'] = new_df['date'].astype(str)\n",
    "\n",
    "y = new_df.unit_sale                                            # getting the label\n",
    "new_df = new_df.drop('unit_sale', axis=1)\n",
    "\n",
    "print('Encoding categorical features...')\n",
    "le, new_df = myfeature.encode_cat_cols(new_df)                  # Encoding Categorical Columns\n",
    "\n",
    "X = new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "We use rows_per_day to decide the location of that dept in X data. Every dept has variable no of rows to it's name.\n",
    "'''\n",
    "\n",
    "ev_train_start, ev_train_end, val_train_start, val_train_end = rows_per_day*(0), rows_per_day*1941,\\\n",
    "                                                               rows_per_day*(0), rows_per_day*1913\n",
    "\n",
    "print('Getting X_train, y_train...')\n",
    "                                                                \n",
    "X_train, y_train = X.iloc[ev_train_start:ev_train_end], y[ev_train_start:ev_train_end] \n",
    "X_test, y_test = X.iloc[ev_train_end:], y[ev_train_end:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
